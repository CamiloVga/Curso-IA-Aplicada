{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/3ITWWr/LqLE50fOdHSqn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CamiloVga/Curso-IA-Aplicada/blob/main/Semana%2011_Arquitectura%20Transformers/GPT_Paso_A_Paso.ipynb)"
  ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simulador de un Bloque GPT\n",
        "\n",
        "**Por [Camilo Vega](https://www.linkedin.com/in/camilo-vega-169084b1/)**\n",
        "\n",
        "## Prop√≥sito\n",
        "\n",
        "Este c√≥digo simula paso a paso las operaciones matem√°ticas dentro de un bloque GPT, visualizando cada etapa del proceso de generaci√≥n de texto desde los embeddings iniciales hasta la predicci√≥n final.\n",
        "\n",
        "## Aspectos T√©cnicos\n",
        "\n",
        "- **Embeddings**: Implementados como una matriz √∫nica con operaci√≥n de lookup\n",
        "- **Atenci√≥n Multi-cabeza**: Con m√°scara causal expl√≠cita (-inf) para garantizar que cada token solo vea el pasado\n",
        "- **Arquitectura Completa**: Incluye todas las capas (normalizaci√≥n, dropouts, conexiones residuales)\n",
        "- **Weight Tying**: Reutilizaci√≥n de la matriz de embeddings para la proyecci√≥n final\n",
        "\n",
        "## Consideraciones\n",
        "\n",
        "- La simulaci√≥n expone matem√°ticamente cada etapa del proceso\n",
        "- El flujo sigue exactamente la estructura de un bloque transformer real\n",
        "- Facilita la comprensi√≥n de c√≥mo los cambios en los par√°metros afectan las predicciones\n",
        "\n",
        "Este simulador sirve como herramienta educativa transparente para entender los fundamentos matem√°ticos de los modelos de lenguaje modernos."
      ],
      "metadata": {
        "id": "zZjmVLMiRzRN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pFNKWunYORNI",
        "outputId": "65260d69-2f5e-4c7e-ed08-2b3c668b047e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ PASO 1: DEFINICI√ìN DEL VOCABULARIO\n",
            "  Vocabulario (6 tokens):\n",
            "  ID 101: 'Juan'\n",
            "  ID 102: 'es'\n",
            "  ID 103: 'muy'\n",
            "  ID 104: 'inteligente'\n",
            "  ID 105: 'fuerte'\n",
            "  ID 106: 'feliz'\n",
            "\n",
            "  Inicializamos matriz de embeddings (6 x 4)\n",
            "\n",
            "üîπ PASO 2: TOKENIZACI√ìN\n",
            "  Texto de entrada: 'Juan es muy'\n",
            "  Tokens: ['Juan', 'es', 'muy']\n",
            "  IDs de tokens: [101, 102, 103]\n",
            "\n",
            "üîπ PASO 3: EMBEDDINGS DE TOKENS\n",
            "  Operaci√≥n matricial: Ids -> Embeddings\n",
            "  X_tok = embedding_matrix[indices]\n",
            "  √çndices en matriz: [0 1 2]\n",
            "\n",
            "  Embeddings extra√≠dos:\n",
            "  'Juan' (ID=101): [0.1 0.2 0.3 0.4]\n",
            "  'es' (ID=102): [0.5 0.6 0.7 0.8]\n",
            "  'muy' (ID=103): [0.9 1.  1.1 1.2]\n",
            "\n",
            "üîπ PASO 4: EMBEDDINGS POSICIONALES\n",
            "  Embeddings posicionales:\n",
            "  Posici√≥n 0: [0.01 0.02 0.03 0.04]\n",
            "  Posici√≥n 1: [0.05 0.06 0.07 0.08]\n",
            "  Posici√≥n 2: [0.09 0.1  0.11 0.12]\n",
            "\n",
            "  Embeddings finales (token + posicional):\n",
            "  'Juan': [0.11 0.22 0.33 0.44]\n",
            "  'es': [0.55 0.66 0.77 0.88]\n",
            "  'muy': [0.99 1.1  1.21 1.32]\n",
            "\n",
            "üîπ PASO 5: BLOQUE GPT COMPLETO\n",
            "  Implementando todos los componentes seg√∫n el diagrama de flujo\n",
            "\n",
            "  1Ô∏è‚É£ NORMALIZACI√ìN INICIAL\n",
            "    Entrada normalizada:\n",
            "    [[-1.341 -0.447  0.447  1.341]\n",
            " [-1.341 -0.447  0.447  1.341]\n",
            " [-1.341 -0.447  0.447  1.341]]\n",
            "\n",
            "  2Ô∏è‚É£ ATENCI√ìN CONTEXTUAL (MULTI-HEAD)\n",
            "    N√∫mero de cabezas: 2\n",
            "    Dimensi√≥n por cabeza: 2\n",
            "\n",
            "    ‚ö° Cabeza de atenci√≥n #1\n",
            "    Q_1:\n",
            "    [-0.045 0.268]\n",
            "    [-0.045 0.268]\n",
            "    [-0.045 0.268]\n",
            "    K_1:\n",
            "    [0.134 -0.045]\n",
            "    [0.134 -0.045]\n",
            "    [0.134 -0.045]\n",
            "    V_1:\n",
            "    [0.089 0.089]\n",
            "    [0.089 0.089]\n",
            "    [0.089 0.089]\n",
            "    Scores de atenci√≥n (QK^T/sqrt(2)):\n",
            "    [-0.013 -0.013 -0.013]\n",
            "    [-0.013 -0.013 -0.013]\n",
            "    [-0.013 -0.013 -0.013]\n",
            "    M√°scara causal (-inf en posiciones futuras):\n",
            "    [-0.000 -1000000000.000 -1000000000.000]\n",
            "    [-0.000 -0.000 -1000000000.000]\n",
            "    [-0.000 -0.000 -0.000]\n",
            "    Scores con m√°scara aplicada:\n",
            "    [-0.013 -1000000000.013 -1000000000.013]\n",
            "    [-0.013 -0.013 -1000000000.013]\n",
            "    [-0.013 -0.013 -0.013]\n",
            "    Pesos de atenci√≥n (softmax):\n",
            "    [1.000 0.000 0.000]\n",
            "    [0.500 0.500 0.000]\n",
            "    [0.333 0.333 0.333]\n",
            "    Salida de la cabeza 1:\n",
            "    [0.089 0.089]\n",
            "    [0.089 0.089]\n",
            "    [0.089 0.089]\n",
            "\n",
            "    ‚ö° Cabeza de atenci√≥n #2\n",
            "    Q_2:\n",
            "    [0.179 -0.179]\n",
            "    [0.179 -0.179]\n",
            "    [0.179 -0.179]\n",
            "    K_2:\n",
            "    [0.179 0.089]\n",
            "    [0.179 0.089]\n",
            "    [0.179 0.089]\n",
            "    V_2:\n",
            "    [-0.179 -0.179]\n",
            "    [-0.179 -0.179]\n",
            "    [-0.179 -0.179]\n",
            "    Scores de atenci√≥n (QK^T/sqrt(2)):\n",
            "    [0.011 0.011 0.011]\n",
            "    [0.011 0.011 0.011]\n",
            "    [0.011 0.011 0.011]\n",
            "    M√°scara causal (-inf en posiciones futuras):\n",
            "    [-0.000 -1000000000.000 -1000000000.000]\n",
            "    [-0.000 -0.000 -1000000000.000]\n",
            "    [-0.000 -0.000 -0.000]\n",
            "    Scores con m√°scara aplicada:\n",
            "    [0.011 -999999999.989 -999999999.989]\n",
            "    [0.011 0.011 -999999999.989]\n",
            "    [0.011 0.011 0.011]\n",
            "    Pesos de atenci√≥n (softmax):\n",
            "    [1.000 0.000 0.000]\n",
            "    [0.500 0.500 0.000]\n",
            "    [0.333 0.333 0.333]\n",
            "    Salida de la cabeza 2:\n",
            "    [-0.179 -0.179]\n",
            "    [-0.179 -0.179]\n",
            "    [-0.179 -0.179]\n",
            "\n",
            "    Salidas concatenadas de ambas cabezas:\n",
            "    Concatenaci√≥n:\n",
            "    [0.089 0.089 -0.179 -0.179]\n",
            "    [0.089 0.089 -0.179 -0.179]\n",
            "    [0.089 0.089 -0.179 -0.179]\n",
            "\n",
            "    Proyecci√≥n final (W_O):\n",
            "    Salida:\n",
            "    [0.018 -0.098 -0.098 0.045]\n",
            "    [0.018 -0.098 -0.098 0.045]\n",
            "    [0.018 -0.098 -0.098 0.045]\n",
            "\n",
            "  3Ô∏è‚É£ DROPOUT (despu√©s de atenci√≥n)\n",
            "    M√°scara de dropout (1=mantener, 0=descartar):\n",
            "    [[1 0 1 1]\n",
            " [1 1 1 1]\n",
            " [1 1 1 0]]\n",
            "    Salida despu√©s de dropout:\n",
            "    [[ 0.02  -0.    -0.109  0.05 ]\n",
            " [ 0.02  -0.109 -0.109  0.05 ]\n",
            " [ 0.02  -0.109 -0.109  0.   ]]\n",
            "\n",
            "  4Ô∏è‚É£ CONEXI√ìN RESIDUAL (primera)\n",
            "    Salida despu√©s de conexi√≥n residual (X + Attn):\n",
            "    [[0.13  0.22  0.221 0.49 ]\n",
            " [0.57  0.551 0.661 0.93 ]\n",
            " [1.01  0.991 1.101 1.32 ]]\n",
            "\n",
            "  5Ô∏è‚É£ RE-NORMALIZACI√ìN\n",
            "    Salida despu√©s de segunda normalizaci√≥n:\n",
            "    [[-1.002 -0.334 -0.329  1.665]\n",
            " [-0.713 -0.84  -0.113  1.665]\n",
            " [-0.73  -0.876 -0.035  1.642]]\n",
            "\n",
            "  6Ô∏è‚É£ PROCESAMIENTO NO LINEAL (FFN con GELU)\n",
            "    Capa interna FFN (despu√©s de GELU):\n",
            "    [[ 0.005 -0.037  0.059  0.01  -0.042  0.065  0.005 -0.037]\n",
            " [ 0.044 -0.07   0.064  0.05  -0.073  0.07   0.044 -0.07 ]\n",
            " [ 0.051 -0.069  0.057  0.056 -0.073  0.063  0.051 -0.069]]\n",
            "\n",
            "    Salida FFN:\n",
            "    [[ 0.04   0.012  0.006  0.05 ]\n",
            " [ 0.056 -0.003  0.022  0.066]\n",
            " [ 0.056 -0.004  0.027  0.066]]\n",
            "\n",
            "  7Ô∏è‚É£ DROPOUT (despu√©s de FFN)\n",
            "    M√°scara de dropout (1=mantener, 0=descartar):\n",
            "    [[1 1 1 1]\n",
            " [1 1 1 1]\n",
            " [1 1 1 1]]\n",
            "    Salida despu√©s de dropout:\n",
            "    [[ 0.044  0.013  0.006  0.056]\n",
            " [ 0.063 -0.004  0.025  0.074]\n",
            " [ 0.062 -0.004  0.03   0.073]]\n",
            "\n",
            "  8Ô∏è‚É£ CONEXI√ìN RESIDUAL FINAL\n",
            "    Salida despu√©s de conexi√≥n residual final:\n",
            "    [[0.174 0.233 0.227 0.545]\n",
            " [0.632 0.547 0.685 1.003]\n",
            " [1.072 0.986 1.131 1.393]]\n",
            "\n",
            "  üîπ NORMALIZACI√ìN FINAL DEL BLOQUE\n",
            "    Salida final normalizada:\n",
            "    [[-0.825 -0.42  -0.465  1.71 ]\n",
            " [-0.491 -0.985 -0.183  1.659]\n",
            " [-0.483 -1.048 -0.099  1.63 ]]\n",
            "\n",
            "üîπ PASO 6: POSTPROCESAMIENTO\n",
            "\n",
            "  1Ô∏è‚É£ PROYECCI√ìN A LOGITS\n",
            "  En modelos reales, se suele usar la misma matriz de embeddings para la proyecci√≥n final\n",
            "  Matriz de proyecci√≥n (transpuesta de matriz de embeddings):\n",
            "  [[0.1 0.5 0.9 1.1 1.5 0.8]\n",
            " [0.2 0.6 1.  1.2 1.2 1.5]\n",
            " [0.3 0.7 1.1 1.3 0.7 1.6]\n",
            " [0.4 0.8 1.2 1.4 0.8 1.9]]\n",
            "\n",
            "  Logits para cada posici√≥n (tokens de entrada):\n",
            "  [[ 0.378  0.378  0.378  0.378 -0.699  1.215]\n",
            " [ 0.363  0.363  0.363  0.363 -0.719  0.989]\n",
            " [ 0.364  0.364  0.364  0.364 -0.747  0.98 ]]\n",
            "\n",
            "  2Ô∏è‚É£ APLICACI√ìN DE SOFTMAX\n",
            "  Logits para el √∫ltimo token (muy):\n",
            "  [ 0.364  0.364  0.364  0.364 -0.747  0.98 ]\n",
            "\n",
            "  Probabilidades para el siguiente token:\n",
            "  Juan        : 0.1618 (16.2%)\n",
            "  es          : 0.1618 (16.2%)\n",
            "  muy         : 0.1618 (16.2%)\n",
            "  inteligente : 0.1618 (16.2%)\n",
            "  fuerte      : 0.0532 (5.3%)\n",
            "  feliz       : 0.2995 (30.0%)\n",
            "\n",
            "  3Ô∏è‚É£ SELECCI√ìN DEL TOKEN M√ÅS PROBABLE\n",
            "  Token con mayor probabilidad: 'feliz' (ID=106)\n",
            "  Probabilidad: 0.2995 (30.0%)\n",
            "\n",
            "  4Ô∏è‚É£ GENERACI√ìN DE TEXTO FINAL\n",
            "  Texto original: 'Juan es muy'\n",
            "  Texto generado: 'Juan es muy feliz'\n",
            "\n",
            "üß† PREDICCI√ìN FINAL: El token m√°s probable despu√©s de 'Juan es muy' es '**feliz**'\n",
            "   Con una probabilidad de 30.0%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# =============================================\n",
        "# SIMULACI√ìN DETALLADA DE UN BLOQUE GPT\n",
        "# EJEMPLO: \"Juan es muy\"\n",
        "# Predicci√≥n esperada: \"feliz\"\n",
        "# =============================================\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configura numpy para una visualizaci√≥n m√°s limpia de matrices\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=100)\n",
        "np.random.seed(42)  # Para reproducibilidad\n",
        "\n",
        "# --------------------------------------------\n",
        "# 1. Definici√≥n de vocabulario\n",
        "# --------------------------------------------\n",
        "print(\"üîπ PASO 1: DEFINICI√ìN DEL VOCABULARIO\")\n",
        "# Definimos un vocabulario simple\n",
        "vocab = {\n",
        "    101: \"Juan\",\n",
        "    102: \"es\",\n",
        "    103: \"muy\",\n",
        "    104: \"inteligente\",\n",
        "    105: \"fuerte\",\n",
        "    106: \"feliz\"\n",
        "}\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 4\n",
        "\n",
        "# Mapeos auxiliares\n",
        "vocab_ids = list(vocab.keys())\n",
        "id_to_index = {id_: idx for idx, id_ in enumerate(vocab_ids)}\n",
        "index_to_id = {idx: id_ for idx, id_ in enumerate(vocab_ids)}\n",
        "\n",
        "print(f\"  Vocabulario ({vocab_size} tokens):\")\n",
        "for token_id, token in vocab.items():\n",
        "    print(f\"  ID {token_id}: '{token}'\")\n",
        "\n",
        "# Inicializamos una matriz de embedding (esto ser√≠a inicializado o preentrenado)\n",
        "# Esta matriz se utilizar√° posteriormente para convertir IDs a embeddings\n",
        "print(\"\\n  Inicializamos matriz de embeddings ({0} x {1})\".format(vocab_size, embedding_dim))\n",
        "# Los valores se asignan para que el resultado sea m√°s interesante (no equiprobable)\n",
        "embedding_matrix = np.array([\n",
        "    [0.1, 0.2, 0.3, 0.4],  # 101: Juan\n",
        "    [0.5, 0.6, 0.7, 0.8],  # 102: es\n",
        "    [0.9, 1.0, 1.1, 1.2],  # 103: muy\n",
        "    [1.1, 1.2, 1.3, 1.4],  # 104: inteligente\n",
        "    [1.5, 1.2, 0.7, 0.8],  # 105: fuerte\n",
        "    [0.8, 1.5, 1.6, 1.9]   # 106: feliz - valores m√°s altos para que sea m√°s probable\n",
        "])\n",
        "\n",
        "# No mostramos la matriz ahora, solo la inicializamos\n",
        "\n",
        "# --------------------------------------------\n",
        "# 2. Tokenizaci√≥n y Entrada de texto\n",
        "# --------------------------------------------\n",
        "print(\"\\nüîπ PASO 2: TOKENIZACI√ìN\")\n",
        "input_text = \"Juan es muy\"\n",
        "tokens = input_text.split()\n",
        "print(f\"  Texto de entrada: '{input_text}'\")\n",
        "print(f\"  Tokens: {tokens}\")\n",
        "\n",
        "# Convertimos de texto a ids (en un modelo real, esto lo hace el tokenizador)\n",
        "token_ids = [101, 102, 103]  # Juan=101, es=102, muy=103\n",
        "print(f\"  IDs de tokens: {token_ids}\")\n",
        "\n",
        "# --------------------------------------------\n",
        "# 3. Embedding Lookup (multiplicaci√≥n por matriz de embeddings)\n",
        "# --------------------------------------------\n",
        "print(\"\\nüîπ PASO 3: EMBEDDINGS DE TOKENS\")\n",
        "print(\"  Operaci√≥n matricial: Ids -> Embeddings\")\n",
        "print(\"  X_tok = embedding_matrix[indices]\")\n",
        "\n",
        "# Conversi√≥n de IDs a √≠ndices de la matriz\n",
        "token_indices = np.array([id_to_index[token_id] for token_id in token_ids])\n",
        "print(f\"  √çndices en matriz: {token_indices}\")\n",
        "\n",
        "# Operaci√≥n de lookup en la matriz de embeddings\n",
        "X_tok = embedding_matrix[token_indices]\n",
        "\n",
        "# Mostramos los embeddings obtenidos para nuestras 3 palabras\n",
        "print(\"\\n  Embeddings extra√≠dos:\")\n",
        "for i, token_id in enumerate(token_ids):\n",
        "    print(f\"  '{vocab[token_id]}' (ID={token_id}): {X_tok[i]}\")\n",
        "\n",
        "# --------------------------------------------\n",
        "# 4. Embeddings Posicionales\n",
        "# --------------------------------------------\n",
        "print(\"\\nüîπ PASO 4: EMBEDDINGS POSICIONALES\")\n",
        "# Los embeddings posicionales codifican la posici√≥n de cada token\n",
        "pos_embeddings = np.array([\n",
        "    [0.01, 0.02, 0.03, 0.04],  # Posici√≥n 0\n",
        "    [0.05, 0.06, 0.07, 0.08],  # Posici√≥n 1\n",
        "    [0.09, 0.10, 0.11, 0.12]   # Posici√≥n 2\n",
        "])\n",
        "\n",
        "print(\"  Embeddings posicionales:\")\n",
        "for i, pos_emb in enumerate(pos_embeddings):\n",
        "    print(f\"  Posici√≥n {i}: {pos_emb}\")\n",
        "\n",
        "# Sumamos embeddings de tokens y posicionales\n",
        "X = X_tok + pos_embeddings\n",
        "print(\"\\n  Embeddings finales (token + posicional):\")\n",
        "for i, token in enumerate(tokens):\n",
        "    print(f\"  '{token}': {X[i]}\")\n",
        "\n",
        "# --------------------------------------------\n",
        "# 5. BLOQUE GPT (Completo)\n",
        "# --------------------------------------------\n",
        "print(\"\\nüîπ PASO 5: BLOQUE GPT COMPLETO\")\n",
        "print(\"  Implementando todos los componentes seg√∫n el diagrama de flujo\")\n",
        "\n",
        "# 5.1 Primera Normalizaci√≥n (LayerNorm)\n",
        "print(\"\\n  1Ô∏è‚É£ NORMALIZACI√ìN INICIAL\")\n",
        "def layer_norm(x, eps=1e-5):\n",
        "    mean = np.mean(x, axis=-1, keepdims=True)\n",
        "    var = np.var(x, axis=-1, keepdims=True)\n",
        "    return (x - mean) / np.sqrt(var + eps)\n",
        "\n",
        "# Funci√≥n para imprimir matrices de forma ordenada\n",
        "def print_matrix(name, matrix):\n",
        "    \"\"\"Imprime una matriz de forma ordenada\"\"\"\n",
        "    print(f\"    {name}:\")\n",
        "    for row in matrix:\n",
        "        row_str = \"    [\"\n",
        "        for val in row:\n",
        "            row_str += f\"{val:.3f} \"\n",
        "        row_str = row_str.rstrip() + \"]\"\n",
        "        print(row_str)\n",
        "\n",
        "X_norm1 = layer_norm(X)\n",
        "print(\"    Entrada normalizada:\")\n",
        "print(f\"    {X_norm1}\")\n",
        "\n",
        "# 5.2 Atenci√≥n Multi-head\n",
        "print(\"\\n  2Ô∏è‚É£ ATENCI√ìN CONTEXTUAL (MULTI-HEAD)\")\n",
        "\n",
        "# Definimos 2 cabezas de atenci√≥n para este ejemplo\n",
        "num_heads = 2\n",
        "d_model = embedding_dim\n",
        "d_head = d_model // num_heads  # Dimensi√≥n por cabeza (2)\n",
        "\n",
        "print(f\"    N√∫mero de cabezas: {num_heads}\")\n",
        "print(f\"    Dimensi√≥n por cabeza: {d_head}\")\n",
        "\n",
        "# Matrices de proyecci√≥n para cada cabeza\n",
        "# Cabeza 1 - La configuramos para que favorezca \"feliz\"\n",
        "W_Q1 = np.array([\n",
        "    [0.1, 0.2],\n",
        "    [0.3, 0.1],\n",
        "    [0.2, 0.4],\n",
        "    [0.1, 0.3]\n",
        "])\n",
        "\n",
        "W_K1 = np.array([\n",
        "    [0.2, 0.3],\n",
        "    [0.1, 0.2],\n",
        "    [0.4, 0.1],\n",
        "    [0.2, 0.3]\n",
        "])\n",
        "\n",
        "W_V1 = np.array([\n",
        "    [0.3, 0.1],\n",
        "    [0.2, 0.4],\n",
        "    [0.1, 0.3],\n",
        "    [0.4, 0.2]\n",
        "])\n",
        "\n",
        "# Cabeza 2 - Tambi√©n configurada para favorecer \"feliz\"\n",
        "W_Q2 = np.array([\n",
        "    [0.2, 0.4],\n",
        "    [0.3, 0.1],\n",
        "    [0.1, 0.3],\n",
        "    [0.4, 0.2]\n",
        "])\n",
        "\n",
        "W_K2 = np.array([\n",
        "    [0.1, 0.3],\n",
        "    [0.4, 0.2],\n",
        "    [0.2, 0.1],\n",
        "    [0.3, 0.4]\n",
        "])\n",
        "\n",
        "W_V2 = np.array([\n",
        "    [0.4, 0.3],\n",
        "    [0.1, 0.2],\n",
        "    [0.3, 0.4],\n",
        "    [0.2, 0.1]\n",
        "])\n",
        "\n",
        "# Funci√≥n softmax para normalizar puntuaciones\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return e_x / e_x.sum(axis=-1, keepdims=True)\n",
        "\n",
        "# Procesamiento de cada cabeza\n",
        "def attention_head(X, W_Q, W_K, W_V, head_idx):\n",
        "    print(f\"\\n    ‚ö° Cabeza de atenci√≥n #{head_idx+1}\")\n",
        "\n",
        "    # Proyecci√≥n Q, K, V\n",
        "    Q = X @ W_Q\n",
        "    K = X @ W_K\n",
        "    V = X @ W_V\n",
        "\n",
        "    print_matrix(f\"Q_{head_idx+1}\", Q)\n",
        "    print_matrix(f\"K_{head_idx+1}\", K)\n",
        "    print_matrix(f\"V_{head_idx+1}\", V)\n",
        "\n",
        "    # Scores de atenci√≥n (QK^T / sqrt(d_k))\n",
        "    d_k = Q.shape[1]  # dimensi√≥n de las claves\n",
        "    scores = Q @ K.T / np.sqrt(d_k)\n",
        "    print_matrix(f\"Scores de atenci√≥n (QK^T/sqrt({d_k}))\", scores)\n",
        "\n",
        "    # M√°scara causal (triu con k=1)\n",
        "    # -inf en la parte superior derecha de la matriz (futuro)\n",
        "    mask = np.triu(np.ones_like(scores), k=1) * -1e9\n",
        "    print_matrix(\"M√°scara causal (-inf en posiciones futuras)\", mask)\n",
        "\n",
        "    # Aplicar m√°scara\n",
        "    masked_scores = scores + mask\n",
        "    print_matrix(\"Scores con m√°scara aplicada\", masked_scores)\n",
        "\n",
        "    # Aplicar softmax para obtener pesos de atenci√≥n\n",
        "    attn_weights = softmax(masked_scores)\n",
        "    print_matrix(\"Pesos de atenci√≥n (softmax)\", attn_weights)\n",
        "\n",
        "    # Multiplicar pesos por valores para obtener la salida\n",
        "    head_output = attn_weights @ V\n",
        "    print_matrix(f\"Salida de la cabeza {head_idx+1}\", head_output)\n",
        "\n",
        "    return head_output\n",
        "\n",
        "# Procesar cada cabeza por separado\n",
        "head1_output = attention_head(X_norm1, W_Q1, W_K1, W_V1, 0)\n",
        "head2_output = attention_head(X_norm1, W_Q2, W_K2, W_V2, 1)\n",
        "\n",
        "# Concatenar las salidas de las cabezas\n",
        "concat_heads = np.concatenate([head1_output, head2_output], axis=-1)\n",
        "print(\"\\n    Salidas concatenadas de ambas cabezas:\")\n",
        "print_matrix(\"Concatenaci√≥n\", concat_heads)\n",
        "\n",
        "# Proyecci√≥n lineal despu√©s de la concatenaci√≥n\n",
        "W_O = np.array([\n",
        "    [0.1, 0.2, 0.3, 0.4],\n",
        "    [0.5, 0.1, 0.0, 0.3],\n",
        "    [0.0, 0.4, 0.2, 0.1],\n",
        "    [0.2, 0.3, 0.5, 0.0],\n",
        "])\n",
        "\n",
        "attn_output = concat_heads @ W_O\n",
        "print(\"\\n    Proyecci√≥n final (W_O):\")\n",
        "print_matrix(\"Salida\", attn_output)\n",
        "\n",
        "# 5.3 Primer Dropout (despu√©s de atenci√≥n)\n",
        "print(\"\\n  3Ô∏è‚É£ DROPOUT (despu√©s de atenci√≥n)\")\n",
        "# Simulamos dropout con una tasa del 10%\n",
        "dropout_rate = 0.1\n",
        "dropout_mask = np.random.binomial(1, 1 - dropout_rate, attn_output.shape)\n",
        "attn_output_dropout = attn_output * dropout_mask / (1 - dropout_rate)  # Scaling para mantener la magnitud\n",
        "print(f\"    M√°scara de dropout (1=mantener, 0=descartar):\\n    {dropout_mask}\")\n",
        "print(f\"    Salida despu√©s de dropout:\\n    {attn_output_dropout}\")\n",
        "\n",
        "# 5.4 Conexi√≥n Residual (primera)\n",
        "print(\"\\n  4Ô∏è‚É£ CONEXI√ìN RESIDUAL (primera)\")\n",
        "residual1 = X + attn_output_dropout\n",
        "print(f\"    Salida despu√©s de conexi√≥n residual (X + Attn):\\n    {residual1}\")\n",
        "\n",
        "# 5.5 Segunda Normalizaci√≥n\n",
        "print(\"\\n  5Ô∏è‚É£ RE-NORMALIZACI√ìN\")\n",
        "X_norm2 = layer_norm(residual1)\n",
        "print(f\"    Salida despu√©s de segunda normalizaci√≥n:\\n    {X_norm2}\")\n",
        "\n",
        "# 5.6 Feed Forward Network (FFN) con GELU\n",
        "print(\"\\n  6Ô∏è‚É£ PROCESAMIENTO NO LINEAL (FFN con GELU)\")\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * np.power(x, 3))))\n",
        "\n",
        "# Capa de expansi√≥n - configurada para favorecer ciertas predicciones\n",
        "d_ff = 8  # Dimensi√≥n interna de la FFN\n",
        "W1 = np.array([\n",
        "    [0.2, 0.1, 0.3, 0.2, 0.1, 0.3, 0.2, 0.1],\n",
        "    [0.1, 0.3, 0.2, 0.1, 0.3, 0.2, 0.1, 0.3],\n",
        "    [0.3, 0.2, 0.1, 0.3, 0.2, 0.1, 0.3, 0.2],\n",
        "    [0.2, 0.1, 0.3, 0.2, 0.1, 0.3, 0.2, 0.1]\n",
        "])\n",
        "b1 = np.array([0.01, 0.02, 0.01, 0.02, 0.01, 0.02, 0.01, 0.02])\n",
        "\n",
        "# Capa de proyecci√≥n de vuelta a d_model\n",
        "W2 = np.array([\n",
        "    [0.2, 0.1, 0.3, 0.2],\n",
        "    [0.1, 0.3, 0.2, 0.1],\n",
        "    [0.3, 0.2, 0.1, 0.3],\n",
        "    [0.2, 0.1, 0.3, 0.2],\n",
        "    [0.1, 0.3, 0.2, 0.1],\n",
        "    [0.3, 0.2, 0.1, 0.3],\n",
        "    [0.2, 0.1, 0.3, 0.2],\n",
        "    [0.1, 0.3, 0.2, 0.1]\n",
        "])\n",
        "b2 = np.array([0.01, 0.02, 0.01, 0.02])\n",
        "\n",
        "# Propagaci√≥n hacia adelante\n",
        "ffn_hidden = X_norm2 @ W1 + b1\n",
        "ffn_hidden_activated = gelu(ffn_hidden)\n",
        "ffn_output = ffn_hidden_activated @ W2 + b2\n",
        "\n",
        "print(\"    Capa interna FFN (despu√©s de GELU):\")\n",
        "print(f\"    {ffn_hidden_activated}\")\n",
        "print(\"\\n    Salida FFN:\")\n",
        "print(f\"    {ffn_output}\")\n",
        "\n",
        "# 5.7 Segundo Dropout (despu√©s del FFN)\n",
        "print(\"\\n  7Ô∏è‚É£ DROPOUT (despu√©s de FFN)\")\n",
        "dropout_mask2 = np.random.binomial(1, 1 - dropout_rate, ffn_output.shape)\n",
        "ffn_output_dropout = ffn_output * dropout_mask2 / (1 - dropout_rate)\n",
        "print(f\"    M√°scara de dropout (1=mantener, 0=descartar):\\n    {dropout_mask2}\")\n",
        "print(f\"    Salida despu√©s de dropout:\\n    {ffn_output_dropout}\")\n",
        "\n",
        "# 5.8 Conexi√≥n Residual Final\n",
        "print(\"\\n  8Ô∏è‚É£ CONEXI√ìN RESIDUAL FINAL\")\n",
        "residual2 = residual1 + ffn_output_dropout\n",
        "print(f\"    Salida despu√©s de conexi√≥n residual final:\\n    {residual2}\")\n",
        "\n",
        "# 5.9 Normalizaci√≥n Final\n",
        "print(\"\\n  üîπ NORMALIZACI√ìN FINAL DEL BLOQUE\")\n",
        "X_out = layer_norm(residual2)\n",
        "print(\"    Salida final normalizada:\")\n",
        "print(f\"    {X_out}\")\n",
        "\n",
        "# --------------------------------------------\n",
        "# 6. POSTPROCESAMIENTO\n",
        "# --------------------------------------------\n",
        "print(\"\\nüîπ PASO 6: POSTPROCESAMIENTO\")\n",
        "\n",
        "# 6.1 Proyecci√≥n lineal (linear head)\n",
        "print(\"\\n  1Ô∏è‚É£ PROYECCI√ìN A LOGITS\")\n",
        "# Usamos la transpuesta de la matriz de embeddings como matriz de proyecci√≥n (weight tying)\n",
        "print(\"  En modelos reales, se suele usar la misma matriz de embeddings para la proyecci√≥n final\")\n",
        "W_proj = embedding_matrix.T  # (4, 6)\n",
        "print(\"  Matriz de proyecci√≥n (transpuesta de matriz de embeddings):\")\n",
        "print(f\"  {W_proj}\")\n",
        "\n",
        "# Calculamos logits para cada posici√≥n\n",
        "logits = X_out @ W_proj\n",
        "print(\"\\n  Logits para cada posici√≥n (tokens de entrada):\")\n",
        "print(f\"  {logits}\")\n",
        "\n",
        "# 6.2 Aplicaci√≥n de softmax\n",
        "print(\"\\n  2Ô∏è‚É£ APLICACI√ìN DE SOFTMAX\")\n",
        "# Extraer los logits de la √∫ltima posici√≥n\n",
        "last_token_logits = logits[-1]\n",
        "print(\"  Logits para el √∫ltimo token (muy):\")\n",
        "print(f\"  {last_token_logits}\")\n",
        "\n",
        "# Aplicar softmax para obtener probabilidades\n",
        "probs = softmax(last_token_logits)\n",
        "print(\"\\n  Probabilidades para el siguiente token:\")\n",
        "for i, prob in enumerate(probs):\n",
        "    token_id = vocab_ids[i]\n",
        "    print(f\"  {vocab[token_id]:<12}: {prob:.4f} ({prob*100:.1f}%)\")\n",
        "\n",
        "# 6.3 Selecci√≥n del token m√°s probable\n",
        "print(\"\\n  3Ô∏è‚É£ SELECCI√ìN DEL TOKEN M√ÅS PROBABLE\")\n",
        "# Obtener la predicci√≥n\n",
        "pred_idx = np.argmax(probs)\n",
        "pred_id = vocab_ids[pred_idx]\n",
        "pred_token = vocab[pred_id]\n",
        "\n",
        "print(f\"  Token con mayor probabilidad: '{pred_token}' (ID={pred_id})\")\n",
        "print(f\"  Probabilidad: {probs[pred_idx]:.4f} ({probs[pred_idx]*100:.1f}%)\")\n",
        "\n",
        "# 6.4 Generaci√≥n de texto\n",
        "print(\"\\n  4Ô∏è‚É£ GENERACI√ìN DE TEXTO FINAL\")\n",
        "generated_text = f\"Juan es muy {pred_token}\"\n",
        "print(f\"  Texto original: 'Juan es muy'\")\n",
        "print(f\"  Texto generado: '{generated_text}'\")\n",
        "\n",
        "print(f\"\\nüß† PREDICCI√ìN FINAL: El token m√°s probable despu√©s de 'Juan es muy' es '**{pred_token}**'\")\n",
        "print(f\"   Con una probabilidad de {probs[pred_idx]*100:.1f}%\")\n",
        "\n",
        "# Visualizaci√≥n de probabilidades\n",
        "plt.figure(figsize=(10, 5))\n",
        "token_labels = [vocab[id_] for id_ in vocab_ids]\n",
        "plt.bar(token_labels, probs)\n",
        "plt.title('Probabilidades para el siguiente token despu√©s de \"Juan es muy\"')\n",
        "plt.ylabel('Probabilidad')\n",
        "plt.xlabel('Token')\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "for i, p in enumerate(probs):\n",
        "    plt.text(i, p + 0.02, f'{p:.2f}', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('token_probabilities.png')"
      ]
    }
  ]
}
