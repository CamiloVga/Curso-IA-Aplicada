{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOifr9+7elUSbQiL3zVBRR0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CamiloVga/Curso-IA-Aplicada/blob/main/Semana%2009_Fundamentos%20NLP/Script_Clase18_FundamentosNLP_y_Embedings.ipynb)"
  ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Inteligencia Artificial Aplicada para la Econom√≠a\n",
        "## Universidad de los Andes\n",
        "\n",
        "### üë®‚Äçüè´ Profesores\n",
        "- **Profesor Magistral:** Camilo Vega Barbosa\n",
        "- **Asistente de Docencia:** Sergio Julian Zona Moreno\n",
        "\n",
        "### üìö Fundamentos NLP: Similitud Sem√°ntica entre Productos y Categor√≠as\n",
        "Este notebook demuestra la implementaci√≥n pr√°ctica de conceptos fundamentales de Procesamiento de Lenguaje Natural (NLP):\n",
        "\n",
        "1. **Tokenizaci√≥n ‚úÇÔ∏è**\n",
        "   - Divisi√≥n del texto en unidades b√°sicas\n",
        "   - Procesamiento a nivel de palabras\n",
        "   - Manejo de t√©rminos compuestos\n",
        "\n",
        "2. **Normalizaci√≥n üßπ**\n",
        "   - Conversi√≥n a min√∫sculas\n",
        "   - Lematizaci√≥n\n",
        "   - Eliminaci√≥n de stopwords y puntuaci√≥n\n",
        "\n",
        "3. **Vectorizaci√≥n üî¢**\n",
        "   - Word Embeddings pre-entrenados\n",
        "   - Representaci√≥n vectorial de palabras\n",
        "   - Espacio sem√°ntico multidimensional\n",
        "\n",
        "4. **Similitud de Coseno üìê**\n",
        "   - C√°lculo matem√°tico paso a paso\n",
        "   - Implementaci√≥n optimizada con NumPy\n",
        "   - Interpretaci√≥n de resultados\n",
        "   - Visualizaci√≥n de relaciones sem√°nticas\n",
        "\n",
        "### üéØ Objetivo\n",
        "Identificar relaciones sem√°nticas entre productos de supermercado y sus categor√≠as utilizando:\n",
        "- Embeddings pre-entrenados de SpaCy\n",
        "- C√°lculo de similitud de coseno\n",
        "- Clasificaci√≥n autom√°tica basada en similitud sem√°ntica\n",
        "\n",
        "### üîç Aplicaciones Pr√°cticas:\n",
        "- Sistemas de b√∫squeda sem√°ntica en e-commerce\n",
        "- Categorizaci√≥n autom√°tica de productos\n",
        "- Recomendaciones basadas en similitud\n",
        "- An√°lisis de mercado y agrupamiento\n",
        "\n",
        "### Requisitos T√©cnicos:\n",
        "- **Entorno de Ejecuci√≥n**: Google Colab o Jupyter Notebook\n",
        "- **Bibliotecas Necesarias**:\n",
        "  - spaCy (con modelo espa√±ol: es_core_news_md)\n",
        "  - NumPy\n",
        "  - scikit-learn\n",
        "  - Matplotlib\n",
        "  - Seaborn\n",
        "- **Memoria RAM**: M√≠nimo 4GB recomendados\n",
        "- **Tiempo Estimado**: 15-20 minutos para ejecuci√≥n completa\n",
        "\n"
      ],
      "metadata": {
        "id": "n7YsNjUGhkDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo de Embeddings para productos de supermercado"
      ],
      "metadata": {
        "id": "hJYWQn_xdIC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar las bibliotecas principales\n",
        "!pip install spacy scikit-learn matplotlib seaborn numpy -q\n",
        "\n",
        "# Descargar los modelos de lenguaje de spaCy para espa√±ol y alem√°n\n",
        "!python -m spacy download es_core_news_md -q\n",
        "!python -m spacy download en_core_news_md -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6C29OzOZS-j",
        "outputId": "3c08edc1-1e05-4a17-ea2a-f4dd29da2d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\n",
            "\u001b[38;5;1m‚úò No compatible package found for 'en_core_news_md' (spaCy v3.8.4)\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "EJERCICIO DE SIMILITUD SEM√ÅNTICA: PRODUCTOS Y CATEGOR√çAS DE SUPERMERCADO üõí\n",
        "\n",
        "Este script demuestra el proceso completo de NLP comparando productos de supermercado\n",
        "con sus posibles categor√≠as, mostrando c√≥mo los embeddings capturan relaciones sem√°nticas\n",
        "entre palabras del mismo idioma.\n",
        "\"\"\"\n",
        "\n",
        "# ====================== IMPORTACI√ìN DE BIBLIOTECAS ======================\n",
        "import spacy\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA  # A√±adido para PCA\n",
        "\n",
        "# ====================== DEFINICI√ìN DE FUNCIONES ======================\n",
        "\n",
        "def procesar_palabra(palabra, nlp, mostrar_detalles=True):\n",
        "    \"\"\"\n",
        "    Realiza el proceso completo de NLP en una palabra:\n",
        "    1. Tokenizaci√≥n ‚úÇÔ∏è\n",
        "    2. Normalizaci√≥n üßπ\n",
        "    3. Vectorizaci√≥n üî¢\n",
        "    \"\"\"\n",
        "    # PASO 1: TOKENIZACI√ìN ‚úÇÔ∏è\n",
        "    # Procesamos la palabra con SpaCy\n",
        "    doc = nlp(palabra.lower())  # Convertimos a min√∫sculas para mejorar resultados\n",
        "\n",
        "    if mostrar_detalles:\n",
        "        print(f\"\\nüîç Analizando: '{palabra}'\")\n",
        "\n",
        "        # Mostramos los tokens\n",
        "        print(f\"  ‚úÇÔ∏è Tokenizaci√≥n:\")\n",
        "        for token in doc:\n",
        "            print(f\"    - Token: '{token.text}'\")\n",
        "\n",
        "        # PASO 2: NORMALIZACI√ìN üßπ\n",
        "        print(f\"  üßπ Normalizaci√≥n:\")\n",
        "        for token in doc:\n",
        "            print(f\"    - Original: '{token.text}'\")\n",
        "            print(f\"    - Min√∫sculas: '{token.text.lower()}'\")\n",
        "            print(f\"    - Lema: '{token.lemma_}'\")\n",
        "\n",
        "        # PASO 3: VECTORIZACI√ìN üî¢\n",
        "        print(f\"  üî¢ Vectorizaci√≥n:\")\n",
        "        print(f\"    - Dimensiones del vector: {doc.vector.shape}\")\n",
        "\n",
        "        # Mostramos una peque√±a muestra del vector\n",
        "        print(f\"    - Muestra del vector: {doc.vector[:5]}...\")\n",
        "\n",
        "    # Devolvemos el vector y el documento procesado\n",
        "    return doc.vector, doc\n",
        "\n",
        "def calcular_similitud_productos_categorias(productos, categorias, clasificacion, nlp):\n",
        "    \"\"\"\n",
        "    Calcula y visualiza la matriz de similitud entre productos y categor√≠as.\n",
        "\n",
        "    Args:\n",
        "        productos: Lista de productos\n",
        "        categorias: Lista de categor√≠as\n",
        "        clasificacion: Diccionario que asigna cada producto a su categor√≠a correcta\n",
        "        nlp: Modelo de spaCy cargado\n",
        "    \"\"\"\n",
        "    # Matrices para almacenar vectores y similitudes\n",
        "    vectores_productos = []\n",
        "    vectores_categorias = []\n",
        "    matriz_similitud = np.zeros((len(productos), len(categorias)))\n",
        "\n",
        "    # Procesamos cada producto\n",
        "    print(\"\\nüîÑ PROCESANDO PRODUCTOS\")\n",
        "    for producto in productos:\n",
        "        vector, _ = procesar_palabra(producto, nlp, mostrar_detalles=True)\n",
        "        vectores_productos.append(vector)\n",
        "\n",
        "    # Procesamos cada categor√≠a\n",
        "    print(\"\\nüîÑ PROCESANDO CATEGOR√çAS\")\n",
        "    for categoria in categorias:\n",
        "        vector, _ = procesar_palabra(categoria, nlp, mostrar_detalles=True)\n",
        "        vectores_categorias.append(vector)\n",
        "\n",
        "    # Calculamos la similitud de coseno entre cada producto y categor√≠a\n",
        "    print(\"\\nüìä CALCULANDO MATRIZ DE SIMILITUD\")\n",
        "    for i, vec_producto in enumerate(vectores_productos):\n",
        "        for j, vec_categoria in enumerate(vectores_categorias):\n",
        "            # Preparamos los vectores para calcular similitud de coseno\n",
        "            vec_producto_reshaped = vec_producto.reshape(1, -1)\n",
        "            vec_categoria_reshaped = vec_categoria.reshape(1, -1)\n",
        "\n",
        "            # F√ìRMULA DE SIMILITUD DE COSENO: cos(Œ∏) = (A¬∑B)/(|A|¬∑|B|)\n",
        "            sim = cosine_similarity(vec_producto_reshaped, vec_categoria_reshaped)[0][0]\n",
        "            matriz_similitud[i, j] = sim\n",
        "\n",
        "            # Destacamos si es la categor√≠a correcta\n",
        "            es_categoria_correcta = categorias[j] == clasificacion[productos[i]]\n",
        "            destacado = \"‚úì\" if es_categoria_correcta else \"\"\n",
        "\n",
        "            print(f\"  Similitud entre '{productos[i]}' y '{categorias[j]}': {sim:.4f} {destacado}\")\n",
        "\n",
        "    # Visualizamos la matriz de similitud\n",
        "    visualizar_matriz_similitud(productos, categorias, matriz_similitud, clasificacion)\n",
        "\n",
        "    # Encontramos las mejores coincidencias\n",
        "    encontrar_mejores_coincidencias(productos, categorias, matriz_similitud, clasificacion)\n",
        "\n",
        "    return matriz_similitud, vectores_productos, vectores_categorias\n",
        "\n",
        "def visualizar_matriz_similitud(productos, categorias, matriz_similitud, clasificacion):\n",
        "    \"\"\"\n",
        "    Visualiza la matriz de similitud entre productos y categor√≠as como un mapa de calor.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Creamos el mapa de calor con etiquetas arriba\n",
        "    ax = sns.heatmap(\n",
        "        matriz_similitud,\n",
        "        annot=True,\n",
        "        fmt=\".2f\",\n",
        "        cmap=\"Blues\",\n",
        "        xticklabels=categorias,\n",
        "        yticklabels=productos,\n",
        "        vmin=0,\n",
        "        vmax=1,\n",
        "        cbar_kws={'label': 'Similitud de Coseno'}\n",
        "    )\n",
        "\n",
        "    # Colocamos las etiquetas de columnas (categor√≠as) en la parte superior\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.xaxis.set_label_position('top')\n",
        "\n",
        "    # A√±adimos un marcador para las categor√≠as correctas\n",
        "    # Creamos un diccionario inverso para encontrar √≠ndices\n",
        "    indices_cat = {cat: i for i, cat in enumerate(categorias)}\n",
        "\n",
        "    for i, producto in enumerate(productos):\n",
        "        categoria_correcta = clasificacion[producto]\n",
        "        j = indices_cat[categoria_correcta]\n",
        "\n",
        "        # Dibujamos un rect√°ngulo alrededor de la categor√≠a correcta\n",
        "        ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False,\n",
        "                                 edgecolor='red', lw=2, clip_on=False))\n",
        "\n",
        "    plt.title(\"Similitud de Coseno entre Productos y Categor√≠as\", fontsize=14, pad=20)\n",
        "    plt.xlabel(\"Categor√≠as\", fontsize=12)\n",
        "    plt.ylabel(\"Productos\", fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def encontrar_mejores_coincidencias(productos, categorias, matriz_similitud, clasificacion):\n",
        "    \"\"\"\n",
        "    Encuentra y muestra las mejores coincidencias entre productos y categor√≠as.\n",
        "    \"\"\"\n",
        "    print(\"\\nüèÜ MEJORES COINCIDENCIAS POR PRODUCTO\")\n",
        "\n",
        "    # Contamos cu√°ntas veces acertamos la categor√≠a correcta\n",
        "    aciertos = 0\n",
        "\n",
        "    for i, producto in enumerate(productos):\n",
        "        # Encontramos la categor√≠a con mayor similitud\n",
        "        mejor_indice = np.argmax(matriz_similitud[i])\n",
        "        mejor_similitud = matriz_similitud[i, mejor_indice]\n",
        "        mejor_categoria = categorias[mejor_indice]\n",
        "\n",
        "        # Verificamos si es la categor√≠a correcta\n",
        "        categoria_correcta = clasificacion[producto]\n",
        "        es_correcta = mejor_categoria == categoria_correcta\n",
        "\n",
        "        if es_correcta:\n",
        "            aciertos += 1\n",
        "            resultado = \"‚úÖ CORRECTO\"\n",
        "        else:\n",
        "            resultado = f\"‚ùå INCORRECTO (deber√≠a ser '{categoria_correcta}')\"\n",
        "\n",
        "        print(f\"  '{producto}' ‚Üí '{mejor_categoria}' (similitud: {mejor_similitud:.4f}) {resultado}\")\n",
        "\n",
        "        # Interpretamos la similitud\n",
        "        if mejor_similitud > 0.7:\n",
        "            interpretacion = \"Alta similitud sem√°ntica\"\n",
        "        elif mejor_similitud > 0.4:\n",
        "            interpretacion = \"Similitud sem√°ntica moderada\"\n",
        "        elif mejor_similitud > 0.2:\n",
        "            interpretacion = \"Baja similitud sem√°ntica\"\n",
        "        else:\n",
        "            interpretacion = \"Similitud muy baja o nula\"\n",
        "\n",
        "        print(f\"    Interpretaci√≥n: {interpretacion}\")\n",
        "\n",
        "    # Mostramos la precisi√≥n general del modelo\n",
        "    precision = aciertos / len(productos) * 100\n",
        "    print(f\"\\nüìà Precisi√≥n del modelo: {precision:.1f}% ({aciertos}/{len(productos)} aciertos)\")\n",
        "\n",
        "def demostrar_frases_vs_palabras(nlp):\n",
        "    \"\"\"\n",
        "    Demuestra c√≥mo los vectores de frases difieren de los vectores de palabras individuales.\n",
        "    \"\"\"\n",
        "    print(\"\\nüß™ DEMOSTRACI√ìN: PALABRAS VS FRASES\")\n",
        "\n",
        "    # Definimos nuestras palabras y frases\n",
        "    palabra = \"tomate\"\n",
        "    frase = \"tomate fresco\"\n",
        "    categoria1 = \"verdura\"\n",
        "    categoria2 = \"fruta\"\n",
        "\n",
        "    # Procesamos con SpaCy\n",
        "    vec_palabra = nlp(palabra.lower()).vector\n",
        "    vec_frase = nlp(frase.lower()).vector\n",
        "    vec_cat1 = nlp(categoria1.lower()).vector\n",
        "    vec_cat2 = nlp(categoria2.lower()).vector\n",
        "\n",
        "    # Calculamos similitudes\n",
        "    sim_palabra_cat1 = cosine_similarity(vec_palabra.reshape(1, -1), vec_cat1.reshape(1, -1))[0][0]\n",
        "    sim_palabra_cat2 = cosine_similarity(vec_palabra.reshape(1, -1), vec_cat2.reshape(1, -1))[0][0]\n",
        "    sim_frase_cat1 = cosine_similarity(vec_frase.reshape(1, -1), vec_cat1.reshape(1, -1))[0][0]\n",
        "    sim_frase_cat2 = cosine_similarity(vec_frase.reshape(1, -1), vec_cat2.reshape(1, -1))[0][0]\n",
        "\n",
        "    print(f\"Comparando similitudes:\")\n",
        "    print(f\"  ‚Ä¢ '{palabra}' con '{categoria1}': {sim_palabra_cat1:.4f}\")\n",
        "    print(f\"  ‚Ä¢ '{palabra}' con '{categoria2}': {sim_palabra_cat2:.4f}\")\n",
        "    print(f\"  ‚Ä¢ '{frase}' con '{categoria1}': {sim_frase_cat1:.4f}\")\n",
        "    print(f\"  ‚Ä¢ '{frase}' con '{categoria2}': {sim_frase_cat2:.4f}\")\n",
        "\n",
        "    # Visualizamos las diferencias\n",
        "    labels = [f\"'{palabra}'-'{categoria1}'\", f\"'{palabra}'-'{categoria2}'\",\n",
        "              f\"'{frase}'-'{categoria1}'\", f\"'{frase}'-'{categoria2}'\"]\n",
        "    valores = [sim_palabra_cat1, sim_palabra_cat2, sim_frase_cat1, sim_frase_cat2]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(labels, valores, color=['blue', 'orange', 'green', 'red'])\n",
        "    plt.ylim(0, max(valores) * 1.2)\n",
        "    plt.title(\"Efecto del Contexto en la Similitud Sem√°ntica\")\n",
        "    plt.ylabel(\"Similitud de Coseno\")\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nüí° CONCLUSI√ìN:\")\n",
        "    print(\"  Este ejemplo muestra c√≥mo SpaCy considera el contexto completo al generar vectores.\")\n",
        "    print(\"  La adici√≥n de 'fresco' modifica la representaci√≥n sem√°ntica del tomate,\")\n",
        "    print(\"  posiblemente acerc√°ndolo m√°s a la categor√≠a de verdura que de fruta.\")\n",
        "\n",
        "def explicar_similitud_coseno(matriz_similitud, productos, categorias, vectores_productos, vectores_categorias):\n",
        "    \"\"\"\n",
        "    Explica el concepto de similitud de coseno con una visualizaci√≥n usando PCA.\n",
        "    Usa los valores ya calculados de la matriz de similitud para mantener consistencia.\n",
        "    \"\"\"\n",
        "    print(\"\\nüìê EXPLICACI√ìN: SIMILITUD DE COSENO\")\n",
        "    print(\"La similitud de coseno mide el √°ngulo entre dos vectores:\")\n",
        "    print(\"  ‚Ä¢ Similitud = 1: Los vectores apuntan en la misma direcci√≥n (conceptos id√©nticos)\")\n",
        "    print(\"  ‚Ä¢ Similitud = 0: Los vectores son perpendiculares (conceptos no relacionados)\")\n",
        "    print(\"  ‚Ä¢ Similitud = -1: Los vectores apuntan en direcciones opuestas (raramente ocurre)\")\n",
        "\n",
        "    # Seleccionamos los productos y categor√≠as espec√≠ficos para la demostraci√≥n\n",
        "    producto_indice = productos.index(\"manzana\")\n",
        "    categoria_relacionada_indice = categorias.index(\"frutas\")\n",
        "    categoria_no_relacionada_indice = categorias.index(\"limpieza\")\n",
        "\n",
        "    palabra1 = productos[producto_indice]\n",
        "    palabra2 = categorias[categoria_relacionada_indice]\n",
        "    palabra3 = categorias[categoria_no_relacionada_indice]\n",
        "\n",
        "    vec1 = vectores_productos[producto_indice]\n",
        "    vec2 = vectores_categorias[categoria_relacionada_indice]\n",
        "    vec3 = vectores_categorias[categoria_no_relacionada_indice]\n",
        "\n",
        "    # Obtenemos las similitudes de la matriz ya calculada para mantener consistencia\n",
        "    sim_12 = matriz_similitud[producto_indice, categoria_relacionada_indice]\n",
        "    sim_13 = matriz_similitud[producto_indice, categoria_no_relacionada_indice]\n",
        "\n",
        "    # Reducir dimensionalidad para visualizaci√≥n (PCA a 2D)\n",
        "    pca = PCA(n_components=2)\n",
        "\n",
        "    # Juntar los vectores para aplicar PCA\n",
        "    vectores_combinados = np.vstack([vec1, vec2, vec3])\n",
        "    vectores_2d = pca.fit_transform(vectores_combinados)\n",
        "\n",
        "    # Extraer los vectores reducidos\n",
        "    vec1_2d = vectores_2d[0]  # Manzana\n",
        "    vec2_2d = vectores_2d[1]  # Fruta\n",
        "    vec3_2d = vectores_2d[2]  # Limpieza\n",
        "\n",
        "    # Crear visualizaci√≥n\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    origen = [0, 0]\n",
        "\n",
        "    # Dibujamos los vectores en 2D\n",
        "    plt.quiver(*origen, *vec1_2d, angles='xy', scale_units='xy', scale=1, color='blue',\n",
        "               label=f'{palabra1}')\n",
        "    plt.quiver(*origen, *vec2_2d, angles='xy', scale_units='xy', scale=1, color='green',\n",
        "               label=f'{palabra2} - sim:{sim_12:.2f}')\n",
        "    plt.quiver(*origen, *vec3_2d, angles='xy', scale_units='xy', scale=1, color='red',\n",
        "               label=f'{palabra3} - sim:{sim_13:.2f}')\n",
        "\n",
        "    # Configurar gr√°fico\n",
        "    plt.grid(True)\n",
        "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
        "    plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.title('Similitud de Coseno: Representaci√≥n Geom√©trica (vectores reales)')\n",
        "\n",
        "    # Calcular √°ngulos para dibujar arcos\n",
        "    angulo1 = np.arctan2(vec1_2d[1], vec1_2d[0])\n",
        "    angulo2 = np.arctan2(vec2_2d[1], vec2_2d[0])\n",
        "    angulo3 = np.arctan2(vec3_2d[1], vec3_2d[0])\n",
        "\n",
        "    # Dibujar arcos para mostrar √°ngulos\n",
        "    radio = 0.2 * min(np.linalg.norm(vec1_2d), np.linalg.norm(vec2_2d), np.linalg.norm(vec3_2d))\n",
        "\n",
        "    t1 = np.linspace(min(angulo1, angulo2), max(angulo1, angulo2), 100)\n",
        "    plt.plot(radio * np.cos(t1), radio * np.sin(t1), 'g-', lw=2, alpha=0.5)\n",
        "\n",
        "    t2 = np.linspace(min(angulo1, angulo3), max(angulo1, angulo3), 100)\n",
        "    plt.plot(radio * np.cos(t2), radio * np.sin(t2), 'r-', lw=2, alpha=0.5)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Explicaci√≥n matem√°tica usando los vectores reales pero con los valores ya calculados\n",
        "    print(\"\\nF√ìRMULA MATEM√ÅTICA:\")\n",
        "    print(\"  similitud_coseno(A, B) = (A¬∑B) / (|A| √ó |B|)\")\n",
        "    print(\"Donde:\")\n",
        "    print(\"  ‚Ä¢ A¬∑B es el producto punto de los vectores\")\n",
        "    print(\"  ‚Ä¢ |A| y |B| son las magnitudes (normas) de los vectores\")\n",
        "    print(\"\\nEjemplo con valores reales de la matriz:\")\n",
        "    print(f\"  ‚Ä¢ Similitud entre '{palabra1}' y '{palabra2}': {sim_12:.4f}\")\n",
        "    print(f\"  ‚Ä¢ Similitud entre '{palabra1}' y '{palabra3}': {sim_13:.4f}\")\n",
        "    print(\"\\nEsta representaci√≥n visual usa PCA para reducir la dimensionalidad de los vectores,\")\n",
        "    print(\"preservando las similitudes calculadas en la matriz anterior.\")\n",
        "\n",
        "# ====================== FUNCI√ìN PRINCIPAL ======================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Funci√≥n principal del programa.\"\"\"\n",
        "    print(\"üõí EJERCICIO DE SIMILITUD SEM√ÅNTICA: PRODUCTOS Y CATEGOR√çAS üõí\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"Este ejercicio demuestra el proceso completo de NLP:\")\n",
        "    print(\"1. Tokenizaci√≥n ‚úÇÔ∏è: Dividir el texto en unidades b√°sicas\")\n",
        "    print(\"2. Normalizaci√≥n üßπ: Estandarizar el texto (min√∫sculas, lematizaci√≥n)\")\n",
        "    print(\"3. Vectorizaci√≥n üî¢: Convertir texto en representaciones num√©ricas\")\n",
        "    print(\"4. Similitud de coseno üìè: Medir la similitud sem√°ntica entre palabras\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Definimos productos y categor√≠as de supermercado\n",
        "    productos = [\n",
        "        \"manzana\", \"detergente\", \"pollo\", \"zanahoria\",\n",
        "        \"shampoo\", \"arroz\", \"at√∫n\", \"pasta\", \"tomate\",\n",
        "        \"jab√≥n\", \"lechuga\", \"cepillo de dientes\"\n",
        "    ]\n",
        "\n",
        "    categorias = [\n",
        "        \"frutas\", \"limpieza\", \"carnes\", \"verduras\",\n",
        "        \"higiene\", \"cereales\", \"pescados\", \"l√°cteos\"\n",
        "    ]\n",
        "\n",
        "    # Clasificaci√≥n correcta de productos (para evaluaci√≥n)\n",
        "    clasificacion = {\n",
        "        \"manzana\": \"frutas\",\n",
        "        \"detergente\": \"limpieza\",\n",
        "        \"pollo\": \"carnes\",\n",
        "        \"zanahoria\": \"verduras\",\n",
        "        \"shampoo\": \"higiene\",\n",
        "        \"arroz\": \"cereales\",\n",
        "        \"at√∫n\": \"pescados\",\n",
        "        \"pasta\": \"cereales\",\n",
        "        \"tomate\": \"verduras\",\n",
        "        \"jab√≥n\": \"higiene\",\n",
        "        \"lechuga\": \"verduras\",\n",
        "        \"cepillo de dientes\": \"higiene\"\n",
        "    }\n",
        "\n",
        "    # Cargamos el modelo de lenguaje de spaCy\n",
        "    print(\"\\nCargando modelo de lenguaje...\")\n",
        "    try:\n",
        "        nlp = spacy.load(\"es_core_news_md\")\n",
        "        print(\"‚úì Modelo espa√±ol cargado\")\n",
        "    except OSError:\n",
        "        print(\"! Modelo espa√±ol no encontrado. Instalando...\")\n",
        "        import subprocess\n",
        "        subprocess.call([\"python\", \"-m\", \"spacy\", \"download\", \"es_core_news_md\"])\n",
        "        nlp = spacy.load(\"es_core_news_md\")\n",
        "\n",
        "    # Demostramos las diferencias entre vectores de palabras y frases\n",
        "    demostrar_frases_vs_palabras(nlp)\n",
        "\n",
        "    # Calculamos la similitud entre productos y categor√≠as\n",
        "    matriz_similitud, vectores_productos, vectores_categorias = calcular_similitud_productos_categorias(\n",
        "        productos,\n",
        "        categorias,\n",
        "        clasificacion,\n",
        "        nlp\n",
        "    )\n",
        "\n",
        "    # Explicamos la similitud de coseno usando los valores de la matriz ya calculada\n",
        "    explicar_similitud_coseno(matriz_similitud, productos, categorias, vectores_productos, vectores_categorias)\n",
        "\n",
        "    print(\"\\nüí° CONCLUSI√ìN\")\n",
        "    print(\"Este ejercicio muestra c√≥mo los modelos de embeddings pueden identificar\")\n",
        "    print(\"relaciones sem√°nticas entre productos y sus categor√≠as dentro del mismo idioma.\")\n",
        "    print(\"Observaciones importantes:\")\n",
        "    print(\"1. La normalizaci√≥n mejora los resultados de similitud\")\n",
        "    print(\"2. Los embeddings capturan relaciones sem√°nticas incluso cuando no hay similitud l√©xica\")\n",
        "    print(\"3. El contexto (palabras adicionales) puede modificar significativamente la representaci√≥n\")\n",
        "    print(\"4. Estos conceptos son fundamentales en aplicaciones como:\")\n",
        "    print(\"   - Sistemas de b√∫squeda sem√°ntica\")\n",
        "    print(\"   - Categorizaci√≥n autom√°tica de productos\")\n",
        "    print(\"   - Recomendaciones basadas en similitud\")\n",
        "    print(\"   - An√°lisis de mercado y agrupamiento\")\n",
        "\n",
        "# ====================== EJECUCI√ìN DEL PROGRAMA ======================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "icup9KtzdUVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo de Embeddings para productos de supermercado en ingl√©s"
      ],
      "metadata": {
        "id": "RagIxm6OdOwT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GznGdpLKZQT_"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "EJERCICIO DE SIMILITUD SEM√ÅNTICA MULTILING√úE: PRODUCTOS DE SUPERMERCADO üõí\n",
        "\n",
        "Este script demuestra el proceso completo de NLP comparando productos de supermercado\n",
        "en espa√±ol e ingl√©s, mostrando c√≥mo los embeddings capturan similitudes sem√°nticas\n",
        "a trav√©s de diferentes idiomas.\n",
        "\"\"\"\n",
        "\n",
        "# ====================== IMPORTACI√ìN DE BIBLIOTECAS ======================\n",
        "import spacy\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA  # A√±adido para PCA\n",
        "\n",
        "# ====================== DEFINICI√ìN DE FUNCIONES ======================\n",
        "\n",
        "def procesar_palabra(palabra, nlp, mostrar_detalles=True):\n",
        "    \"\"\"\n",
        "    Realiza el proceso completo de NLP en una palabra:\n",
        "    1. Tokenizaci√≥n ‚úÇÔ∏è\n",
        "    2. Normalizaci√≥n üßπ\n",
        "    3. Vectorizaci√≥n üî¢\n",
        "    \"\"\"\n",
        "    # PASO 1: TOKENIZACI√ìN ‚úÇÔ∏è\n",
        "    # Procesamos la palabra con SpaCy\n",
        "    doc = nlp(palabra.lower())  # Convertimos a min√∫sculas para mejorar resultados\n",
        "\n",
        "    if mostrar_detalles:\n",
        "        print(f\"\\nüîç Analizando: '{palabra}'\")\n",
        "\n",
        "        # Mostramos los tokens\n",
        "        print(f\"  ‚úÇÔ∏è Tokenizaci√≥n:\")\n",
        "        for token in doc:\n",
        "            print(f\"    - Token: '{token.text}'\")\n",
        "\n",
        "        # PASO 2: NORMALIZACI√ìN üßπ\n",
        "        print(f\"  üßπ Normalizaci√≥n:\")\n",
        "        for token in doc:\n",
        "            print(f\"    - Original: '{token.text}'\")\n",
        "            print(f\"    - Min√∫sculas: '{token.text.lower()}'\")\n",
        "            print(f\"    - Lema: '{token.lemma_}'\")\n",
        "\n",
        "        # PASO 3: VECTORIZACI√ìN üî¢\n",
        "        print(f\"  üî¢ Vectorizaci√≥n:\")\n",
        "        print(f\"    - Dimensiones del vector: {doc.vector.shape}\")\n",
        "\n",
        "        # Mostramos una peque√±a muestra del vector\n",
        "        print(f\"    - Muestra del vector: {doc.vector[:5]}...\")\n",
        "\n",
        "    # Devolvemos el vector y el documento procesado\n",
        "    return doc.vector, doc\n",
        "\n",
        "def calcular_similitud_productos(productos_es, productos_en, traducciones, nlp_es, nlp_en):\n",
        "    \"\"\"\n",
        "    Calcula y visualiza la matriz de similitud entre productos en espa√±ol e ingl√©s.\n",
        "\n",
        "    Args:\n",
        "        productos_es: Lista de productos en espa√±ol\n",
        "        productos_en: Lista de productos en ingl√©s\n",
        "        traducciones: Diccionario con las traducciones correctas\n",
        "        nlp_es: Modelo de spaCy para espa√±ol\n",
        "        nlp_en: Modelo de spaCy para ingl√©s\n",
        "    \"\"\"\n",
        "    # Matrices para almacenar vectores y similitudes\n",
        "    vectores_es = []\n",
        "    vectores_en = []\n",
        "    matriz_similitud = np.zeros((len(productos_es), len(productos_en)))\n",
        "\n",
        "    # Procesamos cada producto en espa√±ol\n",
        "    print(\"\\nüîÑ PROCESANDO PRODUCTOS EN ESPA√ëOL\")\n",
        "    for producto in productos_es:\n",
        "        vector, _ = procesar_palabra(producto, nlp_es, mostrar_detalles=True)\n",
        "        vectores_es.append(vector)\n",
        "\n",
        "    # Procesamos cada producto en ingl√©s\n",
        "    print(\"\\nüîÑ PROCESANDO PRODUCTOS EN INGL√âS\")\n",
        "    for producto in productos_en:\n",
        "        vector, _ = procesar_palabra(producto, nlp_en, mostrar_detalles=True)\n",
        "        vectores_en.append(vector)\n",
        "\n",
        "    # Calculamos la similitud de coseno entre cada par de productos\n",
        "    print(\"\\nüìä CALCULANDO MATRIZ DE SIMILITUD\")\n",
        "    for i, vec_es in enumerate(vectores_es):\n",
        "        for j, vec_en in enumerate(vectores_en):\n",
        "            # Preparamos los vectores para calcular similitud de coseno\n",
        "            vec_es_reshaped = vec_es.reshape(1, -1)\n",
        "            vec_en_reshaped = vec_en.reshape(1, -1)\n",
        "\n",
        "            # F√ìRMULA DE SIMILITUD DE COSENO: cos(Œ∏) = (A¬∑B)/(|A|¬∑|B|)\n",
        "            sim = cosine_similarity(vec_es_reshaped, vec_en_reshaped)[0][0]\n",
        "            matriz_similitud[i, j] = sim\n",
        "\n",
        "            # Destacamos si es la traducci√≥n correcta\n",
        "            es_traduccion = productos_en[j] == traducciones[productos_es[i]]\n",
        "            destacado = \"‚úì\" if es_traduccion else \"\"\n",
        "\n",
        "            print(f\"  Similitud entre '{productos_es[i]}' y '{productos_en[j]}': {sim:.4f} {destacado}\")\n",
        "\n",
        "    # Visualizamos la matriz de similitud\n",
        "    visualizar_matriz_similitud(productos_es, productos_en, matriz_similitud, traducciones)\n",
        "\n",
        "    # Encontramos las mejores coincidencias\n",
        "    encontrar_mejores_coincidencias(productos_es, productos_en, matriz_similitud, traducciones)\n",
        "\n",
        "    return matriz_similitud, vectores_es, vectores_en\n",
        "\n",
        "def visualizar_matriz_similitud(productos_es, productos_en, matriz_similitud, traducciones):\n",
        "    \"\"\"\n",
        "    Visualiza la matriz de similitud entre productos como un mapa de calor.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Creamos el mapa de calor con etiquetas arriba\n",
        "    ax = sns.heatmap(\n",
        "        matriz_similitud,\n",
        "        annot=True,\n",
        "        fmt=\".2f\",\n",
        "        cmap=\"Blues\",\n",
        "        xticklabels=productos_en,\n",
        "        yticklabels=productos_es,\n",
        "        vmin=-0.1,\n",
        "        vmax=1,\n",
        "        cbar_kws={'label': 'Similitud de Coseno'}\n",
        "    )\n",
        "\n",
        "    # Colocamos las etiquetas de columnas (productos ingleses) en la parte superior\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.xaxis.set_label_position('top')\n",
        "\n",
        "    # A√±adimos un marcador para las traducciones correctas\n",
        "    # Creamos un diccionario inverso para encontrar √≠ndices\n",
        "    indices_en = {prod: i for i, prod in enumerate(productos_en)}\n",
        "\n",
        "    for i, prod_es in enumerate(productos_es):\n",
        "        traduccion = traducciones[prod_es]\n",
        "        j = indices_en[traduccion]\n",
        "\n",
        "        # Dibujamos un rect√°ngulo alrededor de la traducci√≥n correcta\n",
        "        ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False,\n",
        "                                 edgecolor='red', lw=2, clip_on=False))\n",
        "\n",
        "    plt.title(\"Similitud de Coseno entre Productos (Espa√±ol - Ingl√©s)\", fontsize=14, pad=20)\n",
        "    plt.xlabel(\"Productos en Ingl√©s\", fontsize=12)\n",
        "    plt.ylabel(\"Productos en Espa√±ol\", fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def encontrar_mejores_coincidencias(productos_es, productos_en, matriz_similitud, traducciones):\n",
        "    \"\"\"\n",
        "    Encuentra y muestra las mejores coincidencias entre productos.\n",
        "    \"\"\"\n",
        "    print(\"\\nüèÜ MEJORES COINCIDENCIAS POR PRODUCTO\")\n",
        "\n",
        "    # Contamos cu√°ntas veces acertamos la traducci√≥n correcta\n",
        "    aciertos = 0\n",
        "\n",
        "    for i, producto_es in enumerate(productos_es):\n",
        "        # Encontramos el producto ingl√©s con mayor similitud\n",
        "        mejor_indice = np.argmax(matriz_similitud[i])\n",
        "        mejor_similitud = matriz_similitud[i, mejor_indice]\n",
        "        mejor_producto_en = productos_en[mejor_indice]\n",
        "\n",
        "        # Verificamos si es la traducci√≥n correcta\n",
        "        traduccion_correcta = traducciones[producto_es]\n",
        "        es_correcta = mejor_producto_en == traduccion_correcta\n",
        "\n",
        "        if es_correcta:\n",
        "            aciertos += 1\n",
        "            resultado = \"‚úÖ CORRECTO\"\n",
        "        else:\n",
        "            resultado = f\"‚ùå INCORRECTO (deber√≠a ser '{traduccion_correcta}')\"\n",
        "\n",
        "        print(f\"  '{producto_es}' ‚Üí '{mejor_producto_en}' (similitud: {mejor_similitud:.4f}) {resultado}\")\n",
        "\n",
        "        # Interpretamos la similitud\n",
        "        if mejor_similitud > 0.7:\n",
        "            interpretacion = \"Alta similitud sem√°ntica\"\n",
        "        elif mejor_similitud > 0.4:\n",
        "            interpretacion = \"Similitud sem√°ntica moderada\"\n",
        "        elif mejor_similitud > 0.2:\n",
        "            interpretacion = \"Baja similitud sem√°ntica\"\n",
        "        else:\n",
        "            interpretacion = \"Similitud muy baja o nula\"\n",
        "\n",
        "        print(f\"    Interpretaci√≥n: {interpretacion}\")\n",
        "\n",
        "    # Mostramos la precisi√≥n general del modelo\n",
        "    precision = aciertos / len(productos_es) * 100\n",
        "    print(f\"\\nüìà Precisi√≥n del modelo: {precision:.1f}% ({aciertos}/{len(productos_es)} aciertos)\")\n",
        "\n",
        "def demostrar_mejora_normalizacion(palabra_es, palabra_en, nlp_es, nlp_en):\n",
        "    \"\"\"\n",
        "    Demuestra la importancia de la normalizaci√≥n comparando similitudes.\n",
        "    \"\"\"\n",
        "    print(\"\\nüß™ DEMOSTRACI√ìN: IMPORTANCIA DE LA NORMALIZACI√ìN\")\n",
        "\n",
        "    # Sin normalizaci√≥n\n",
        "    doc_es_orig = nlp_es(palabra_es)\n",
        "    doc_en_orig = nlp_en(palabra_en)\n",
        "\n",
        "    # Con normalizaci√≥n (min√∫sculas)\n",
        "    doc_es_norm = nlp_es(palabra_es.lower())\n",
        "    doc_en_norm = nlp_en(palabra_en.lower())\n",
        "\n",
        "    # Calculamos similitudes\n",
        "    sim_orig = cosine_similarity(\n",
        "        doc_es_orig.vector.reshape(1, -1),\n",
        "        doc_en_orig.vector.reshape(1, -1)\n",
        "    )[0][0]\n",
        "\n",
        "    sim_norm = cosine_similarity(\n",
        "        doc_es_norm.vector.reshape(1, -1),\n",
        "        doc_en_norm.vector.reshape(1, -1)\n",
        "    )[0][0]\n",
        "\n",
        "    print(f\"Comparando '{palabra_es}' con '{palabra_en}':\")\n",
        "    print(f\"  ‚Ä¢ Similitud SIN normalizaci√≥n: {sim_orig:.4f}\")\n",
        "    print(f\"  ‚Ä¢ Similitud CON normalizaci√≥n: {sim_norm:.4f}\")\n",
        "    print(f\"  ‚Ä¢ Mejora: {(sim_norm - sim_orig):.4f} ({(sim_norm - sim_orig) / max(0.0001, abs(sim_orig)) * 100:.1f}%)\")\n",
        "\n",
        "def explicar_similitud_coseno(matriz_similitud, productos_es, productos_en, vectores_es, vectores_en, traducciones):\n",
        "    \"\"\"\n",
        "    Explica el concepto de similitud de coseno con una visualizaci√≥n usando PCA.\n",
        "    Usa los valores ya calculados de la matriz de similitud para mantener consistencia.\n",
        "    \"\"\"\n",
        "    print(\"\\nüìê EXPLICACI√ìN: SIMILITUD DE COSENO\")\n",
        "    print(\"La similitud de coseno mide el √°ngulo entre dos vectores:\")\n",
        "    print(\"  ‚Ä¢ Similitud = 1: Los vectores apuntan en la misma direcci√≥n (productos id√©nticos)\")\n",
        "    print(\"  ‚Ä¢ Similitud = 0: Los vectores son perpendiculares (productos no relacionados)\")\n",
        "    print(\"  ‚Ä¢ Similitud = -1: Los vectores apuntan en direcciones opuestas (raramente ocurre)\")\n",
        "\n",
        "    # Seleccionamos los productos espec√≠ficos para la demostraci√≥n\n",
        "    palabra_es = \"pan\"  # Producto en espa√±ol\n",
        "    palabra_en_relacionada = \"bread\"  # Traducci√≥n correcta\n",
        "    palabra_en_no_relacionada = \"soap\"  # Palabra no relacionada\n",
        "\n",
        "    # Encontramos los √≠ndices en nuestras listas\n",
        "    indice_es = productos_es.index(palabra_es)\n",
        "    indice_en_rel = productos_en.index(palabra_en_relacionada)\n",
        "    indice_en_no_rel = productos_en.index(palabra_en_no_relacionada)\n",
        "\n",
        "    # Extraemos los vectores\n",
        "    vec1 = vectores_es[indice_es]\n",
        "    vec2 = vectores_en[indice_en_rel]\n",
        "    vec3 = vectores_en[indice_en_no_rel]\n",
        "\n",
        "    # Obtenemos las similitudes de la matriz ya calculada para mantener consistencia\n",
        "    sim_12 = matriz_similitud[indice_es, indice_en_rel]\n",
        "    sim_13 = matriz_similitud[indice_es, indice_en_no_rel]\n",
        "\n",
        "    # Reducir dimensionalidad para visualizaci√≥n (PCA a 2D)\n",
        "    pca = PCA(n_components=2)\n",
        "\n",
        "    # Juntar los vectores para aplicar PCA\n",
        "    vectores_combinados = np.vstack([vec1, vec2, vec3])\n",
        "    vectores_2d = pca.fit_transform(vectores_combinados)\n",
        "\n",
        "    # Extraer los vectores reducidos\n",
        "    vec1_2d = vectores_2d[0]  # Pan\n",
        "    vec2_2d = vectores_2d[1]  # Bread\n",
        "    vec3_2d = vectores_2d[2]  # Soap\n",
        "\n",
        "    # Crear visualizaci√≥n\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    origen = [0, 0]\n",
        "\n",
        "    # Dibujamos los vectores en 2D\n",
        "    plt.quiver(*origen, *vec1_2d, angles='xy', scale_units='xy', scale=1, color='blue',\n",
        "               label=f'{palabra_es} (espa√±ol)')\n",
        "    plt.quiver(*origen, *vec2_2d, angles='xy', scale_units='xy', scale=1, color='green',\n",
        "               label=f'{palabra_en_relacionada} (ingl√©s) - sim:{sim_12:.2f}')\n",
        "    plt.quiver(*origen, *vec3_2d, angles='xy', scale_units='xy', scale=1, color='red',\n",
        "               label=f'{palabra_en_no_relacionada} (ingl√©s) - sim:{sim_13:.2f}')\n",
        "\n",
        "    # Configurar gr√°fico\n",
        "    plt.grid(True)\n",
        "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
        "    plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.title('Similitud de Coseno: Representaci√≥n Geom√©trica (vectores reales)')\n",
        "\n",
        "    # Calcular √°ngulos para dibujar arcos\n",
        "    angulo1 = np.arctan2(vec1_2d[1], vec1_2d[0])\n",
        "    angulo2 = np.arctan2(vec2_2d[1], vec2_2d[0])\n",
        "    angulo3 = np.arctan2(vec3_2d[1], vec3_2d[0])\n",
        "\n",
        "    # Dibujar arcos para mostrar √°ngulos\n",
        "    radio = 0.2 * min(np.linalg.norm(vec1_2d), np.linalg.norm(vec2_2d), np.linalg.norm(vec3_2d))\n",
        "\n",
        "    t1 = np.linspace(min(angulo1, angulo2), max(angulo1, angulo2), 100)\n",
        "    plt.plot(radio * np.cos(t1), radio * np.sin(t1), 'g-', lw=2, alpha=0.5)\n",
        "\n",
        "    t2 = np.linspace(min(angulo1, angulo3), max(angulo1, angulo3), 100)\n",
        "    plt.plot(radio * np.cos(t2), radio * np.sin(t2), 'r-', lw=2, alpha=0.5)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Explicaci√≥n matem√°tica usando los valores ya calculados\n",
        "    print(\"\\nF√ìRMULA MATEM√ÅTICA:\")\n",
        "    print(\"  similitud_coseno(A, B) = (A¬∑B) / (|A| √ó |B|)\")\n",
        "    print(\"Donde:\")\n",
        "    print(\"  ‚Ä¢ A¬∑B es el producto punto de los vectores\")\n",
        "    print(\"  ‚Ä¢ |A| y |B| son las magnitudes (normas) de los vectores\")\n",
        "    print(\"\\nEjemplo con valores reales de la matriz:\")\n",
        "    print(f\"  ‚Ä¢ Similitud entre '{palabra_es}' y '{palabra_en_relacionada}': {sim_12:.4f}\")\n",
        "    print(f\"  ‚Ä¢ Similitud entre '{palabra_es}' y '{palabra_en_no_relacionada}': {sim_13:.4f}\")\n",
        "    print(\"\\nEsta representaci√≥n visual usa PCA para reducir la dimensionalidad de los vectores,\")\n",
        "    print(\"preservando las similitudes calculadas en la matriz anterior.\")\n",
        "\n",
        "# ====================== FUNCI√ìN PRINCIPAL ======================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Funci√≥n principal del programa.\"\"\"\n",
        "    print(\"üõí EJERCICIO DE SIMILITUD SEM√ÅNTICA: PRODUCTOS DE SUPERMERCADO üõí\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"Este ejercicio demuestra el proceso completo de NLP:\")\n",
        "    print(\"1. Tokenizaci√≥n ‚úÇÔ∏è: Dividir el texto en unidades b√°sicas\")\n",
        "    print(\"2. Normalizaci√≥n üßπ: Estandarizar el texto (min√∫sculas, lematizaci√≥n)\")\n",
        "    print(\"3. Vectorizaci√≥n üî¢: Convertir texto en representaciones num√©ricas\")\n",
        "    print(\"4. Similitud de coseno üìè: Medir la similitud sem√°ntica entre palabras en diferentes idiomas\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Definimos productos de supermercado en espa√±ol e ingl√©s\n",
        "    productos_espanol = [\"pan\", \"leche\", \"manzana\", \"cebolla\", \"jab√≥n\", \"huevos\", \"queso\"]\n",
        "    productos_ingles = [\"bread\", \"milk\", \"apple\", \"onion\", \"soap\", \"eggs\", \"cheese\"]\n",
        "\n",
        "    # Diccionario de traducciones correctas para verificaci√≥n\n",
        "    traducciones = {\n",
        "        \"pan\": \"bread\",\n",
        "        \"leche\": \"milk\",\n",
        "        \"manzana\": \"apple\",\n",
        "        \"cebolla\": \"onion\",\n",
        "        \"jab√≥n\": \"soap\",\n",
        "        \"huevos\": \"eggs\",\n",
        "        \"queso\": \"cheese\"\n",
        "    }\n",
        "\n",
        "    # Cargamos los modelos de lenguaje de spaCy\n",
        "    print(\"\\nCargando modelos de lenguaje...\")\n",
        "    try:\n",
        "        nlp_es = spacy.load(\"es_core_news_md\")\n",
        "        print(\"‚úì Modelo espa√±ol cargado\")\n",
        "    except OSError:\n",
        "        print(\"! Modelo espa√±ol no encontrado. Instalando...\")\n",
        "        import subprocess\n",
        "        subprocess.call([\"python\", \"-m\", \"spacy\", \"download\", \"es_core_news_md\"])\n",
        "        nlp_es = spacy.load(\"es_core_news_md\")\n",
        "\n",
        "    try:\n",
        "        nlp_en = spacy.load(\"en_core_web_md\")\n",
        "        print(\"‚úì Modelo ingl√©s cargado\")\n",
        "    except OSError:\n",
        "        print(\"! Modelo ingl√©s no encontrado. Instalando...\")\n",
        "        import subprocess\n",
        "        subprocess.call([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_md\"])\n",
        "        nlp_en = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "    # Demostramos la importancia de la normalizaci√≥n\n",
        "    demostrar_mejora_normalizacion(\"Pan\", \"Bread\", nlp_es, nlp_en)\n",
        "\n",
        "    # Calculamos la similitud entre productos\n",
        "    matriz_similitud, vectores_es, vectores_en = calcular_similitud_productos(\n",
        "        productos_espanol,\n",
        "        productos_ingles,\n",
        "        traducciones,\n",
        "        nlp_es,\n",
        "        nlp_en\n",
        "    )\n",
        "\n",
        "    # Explicamos la similitud de coseno usando los valores de la matriz ya calculada\n",
        "    explicar_similitud_coseno(matriz_similitud, productos_espanol, productos_ingles,\n",
        "                             vectores_es, vectores_en, traducciones)\n",
        "\n",
        "print(\"\\nüí° CONCLUSI√ìN\")\n",
        "print(\"Este ejercicio demuestra una limitaci√≥n importante de los embeddings independientes por idioma:\")\n",
        "print(\"1. Los valores de similitud entre palabras equivalentes en diferentes idiomas\")\n",
        "print(\"   son extremadamente bajos (cercanos a 0) porque los espacios vectoriales no est√°n alineados\")\n",
        "print(\"2. Para obtener similitudes sem√°nticas significativas entre idiomas, se necesitar√≠an:\")\n",
        "print(\"   - Embeddings multiling√ºes espec√≠ficamente entrenados (como MUSE, XLM-R o LaBSE)\")\n",
        "print(\"   - T√©cnicas de alineamiento de espacios vectoriales\")\n",
        "print(\"3. Los modelos de SpaCy est√°ndar no est√°n dise√±ados para comparaciones multiling√ºes\")\n",
        "print(\"4. Esta limitaci√≥n es cr√≠tica para aplicaciones como:\")\n",
        "print(\"   - B√∫squeda multiling√ºe\")\n",
        "print(\"   - Sistemas de recomendaci√≥n internacionales\")\n",
        "print(\"   - Traducci√≥n autom√°tica\")\n",
        "\n",
        "# ====================== EJECUCI√ìN DEL PROGRAMA ======================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo de Embeddings Bilingues"
      ],
      "metadata": {
        "id": "83emF0cLdW-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "EJERCICIO DE SIMILITUD SEM√ÅNTICA MULTILING√úE MEJORADO: PRODUCTOS DE SUPERMERCADO üõí\n",
        "\n",
        "Este script demuestra el proceso de NLP para comparar productos de supermercado\n",
        "en espa√±ol e ingl√©s usando embeddings multiling√ºes, mostrando mejores resultados\n",
        "en la captura de similitudes sem√°nticas entre diferentes idiomas.\n",
        "\"\"\"\n",
        "\n",
        "# ====================== IMPORTACI√ìN DE BIBLIOTECAS ======================\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Instalamos sentence-transformers si es necesario reiniciar\n",
        "# !pip install -q sentence-transformers\n",
        "\n",
        "# Importamos SentenceTransformer para embeddings multiling√ºes\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# ====================== DEFINICI√ìN DE FUNCIONES ======================\n",
        "\n",
        "def procesar_palabra(palabra, modelo, mostrar_detalles=True):\n",
        "    \"\"\"\n",
        "    Realiza el proceso de embedding para una palabra usando un modelo multiling√ºe:\n",
        "    1. Normalizaci√≥n üßπ\n",
        "    2. Vectorizaci√≥n con embedding multiling√ºe üî¢\n",
        "    \"\"\"\n",
        "    # Normalizamos la palabra (min√∫sculas)\n",
        "    palabra_norm = palabra.lower()\n",
        "\n",
        "    # Generamos el embedding\n",
        "    vector = modelo.encode(palabra_norm)\n",
        "\n",
        "    if mostrar_detalles:\n",
        "        print(f\"\\nüîç Analizando: '{palabra}'\")\n",
        "\n",
        "        # PASO 1: NORMALIZACI√ìN üßπ\n",
        "        print(f\"  üßπ Normalizaci√≥n:\")\n",
        "        print(f\"    - Original: '{palabra}'\")\n",
        "        print(f\"    - Min√∫sculas: '{palabra_norm}'\")\n",
        "\n",
        "        # PASO 2: VECTORIZACI√ìN üî¢\n",
        "        print(f\"  üî¢ Vectorizaci√≥n (embedding multiling√ºe):\")\n",
        "        print(f\"    - Dimensiones del vector: {vector.shape}\")\n",
        "        print(f\"    - Muestra del vector: {vector[:5]}...\")\n",
        "\n",
        "    # Devolvemos el vector procesado\n",
        "    return vector\n",
        "\n",
        "def calcular_similitud_productos(productos_es, productos_en, traducciones, modelo):\n",
        "    \"\"\"\n",
        "    Calcula y visualiza la matriz de similitud entre productos en espa√±ol e ingl√©s.\n",
        "\n",
        "    Args:\n",
        "        productos_es: Lista de productos en espa√±ol\n",
        "        productos_en: Lista de productos en ingl√©s\n",
        "        traducciones: Diccionario con las traducciones correctas\n",
        "        modelo: Modelo de embedding multiling√ºe\n",
        "    \"\"\"\n",
        "    # Matrices para almacenar vectores y similitudes\n",
        "    vectores_es = []\n",
        "    vectores_en = []\n",
        "    matriz_similitud = np.zeros((len(productos_es), len(productos_en)))\n",
        "\n",
        "    # Procesamos cada producto en espa√±ol\n",
        "    print(\"\\nüîÑ PROCESANDO PRODUCTOS EN ESPA√ëOL\")\n",
        "    for producto in productos_es:\n",
        "        vector = procesar_palabra(producto, modelo, mostrar_detalles=True)\n",
        "        vectores_es.append(vector)\n",
        "\n",
        "    # Procesamos cada producto en ingl√©s\n",
        "    print(\"\\nüîÑ PROCESANDO PRODUCTOS EN INGL√âS\")\n",
        "    for producto in productos_en:\n",
        "        vector = procesar_palabra(producto, modelo, mostrar_detalles=True)\n",
        "        vectores_en.append(vector)\n",
        "\n",
        "    # Calculamos la similitud de coseno entre cada par de productos\n",
        "    print(\"\\nüìä CALCULANDO MATRIZ DE SIMILITUD\")\n",
        "    for i, vec_es in enumerate(vectores_es):\n",
        "        for j, vec_en in enumerate(vectores_en):\n",
        "            # Preparamos los vectores para calcular similitud de coseno\n",
        "            vec_es_reshaped = vec_es.reshape(1, -1)\n",
        "            vec_en_reshaped = vec_en.reshape(1, -1)\n",
        "\n",
        "            # F√ìRMULA DE SIMILITUD DE COSENO: cos(Œ∏) = (A¬∑B)/(|A|¬∑|B|)\n",
        "            sim = cosine_similarity(vec_es_reshaped, vec_en_reshaped)[0][0]\n",
        "            matriz_similitud[i, j] = sim\n",
        "\n",
        "            # Destacamos si es la traducci√≥n correcta\n",
        "            es_traduccion = productos_en[j] == traducciones[productos_es[i]]\n",
        "            destacado = \"‚úì\" if es_traduccion else \"\"\n",
        "\n",
        "            print(f\"  Similitud entre '{productos_es[i]}' y '{productos_en[j]}': {sim:.4f} {destacado}\")\n",
        "\n",
        "    # Visualizamos la matriz de similitud\n",
        "    visualizar_matriz_similitud(productos_es, productos_en, matriz_similitud, traducciones)\n",
        "\n",
        "    # Encontramos las mejores coincidencias\n",
        "    encontrar_mejores_coincidencias(productos_es, productos_en, matriz_similitud, traducciones)\n",
        "\n",
        "    # Almacenar los resultados para usar en la visualizaci√≥n\n",
        "    return matriz_similitud, vectores_es, vectores_en\n",
        "\n",
        "def visualizar_matriz_similitud(productos_es, productos_en, matriz_similitud, traducciones):\n",
        "    \"\"\"\n",
        "    Visualiza la matriz de similitud entre productos como un mapa de calor.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Creamos el mapa de calor con etiquetas arriba\n",
        "    ax = sns.heatmap(\n",
        "        matriz_similitud,\n",
        "        annot=True,\n",
        "        fmt=\".2f\",\n",
        "        cmap=\"Blues\",\n",
        "        xticklabels=productos_en,\n",
        "        yticklabels=productos_es,\n",
        "        vmin=-0.1,\n",
        "        vmax=1,\n",
        "        cbar_kws={'label': 'Similitud de Coseno'}\n",
        "    )\n",
        "\n",
        "    # Colocamos las etiquetas de columnas (productos ingleses) en la parte superior\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.xaxis.set_label_position('top')\n",
        "\n",
        "    # A√±adimos un marcador para las traducciones correctas\n",
        "    # Creamos un diccionario inverso para encontrar √≠ndices\n",
        "    indices_en = {prod: i for i, prod in enumerate(productos_en)}\n",
        "\n",
        "    for i, prod_es in enumerate(productos_es):\n",
        "        traduccion = traducciones[prod_es]\n",
        "        j = indices_en[traduccion]\n",
        "\n",
        "        # Dibujamos un rect√°ngulo alrededor de la traducci√≥n correcta\n",
        "        ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False,\n",
        "                                 edgecolor='red', lw=2, clip_on=False))\n",
        "\n",
        "    plt.title(\"Similitud de Coseno entre Productos (Espa√±ol - Ingl√©s)\", fontsize=14, pad=20)\n",
        "    plt.xlabel(\"Productos en Ingl√©s\", fontsize=12)\n",
        "    plt.ylabel(\"Productos en Espa√±ol\", fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def encontrar_mejores_coincidencias(productos_es, productos_en, matriz_similitud, traducciones):\n",
        "    \"\"\"\n",
        "    Encuentra y muestra las mejores coincidencias entre productos.\n",
        "    \"\"\"\n",
        "    print(\"\\nüèÜ MEJORES COINCIDENCIAS POR PRODUCTO\")\n",
        "\n",
        "    # Contamos cu√°ntas veces acertamos la traducci√≥n correcta\n",
        "    aciertos = 0\n",
        "\n",
        "    for i, producto_es in enumerate(productos_es):\n",
        "        # Encontramos el producto ingl√©s con mayor similitud\n",
        "        mejor_indice = np.argmax(matriz_similitud[i])\n",
        "        mejor_similitud = matriz_similitud[i, mejor_indice]\n",
        "        mejor_producto_en = productos_en[mejor_indice]\n",
        "\n",
        "        # Verificamos si es la traducci√≥n correcta\n",
        "        traduccion_correcta = traducciones[producto_es]\n",
        "        es_correcta = mejor_producto_en == traduccion_correcta\n",
        "\n",
        "        if es_correcta:\n",
        "            aciertos += 1\n",
        "            resultado = \"‚úÖ CORRECTO\"\n",
        "        else:\n",
        "            resultado = f\"‚ùå INCORRECTO (deber√≠a ser '{traduccion_correcta}')\"\n",
        "\n",
        "        print(f\"  '{producto_es}' ‚Üí '{mejor_producto_en}' (similitud: {mejor_similitud:.4f}) {resultado}\")\n",
        "\n",
        "        # Interpretamos la similitud\n",
        "        if mejor_similitud > 0.7:\n",
        "            interpretacion = \"Alta similitud sem√°ntica\"\n",
        "        elif mejor_similitud > 0.4:\n",
        "            interpretacion = \"Similitud sem√°ntica moderada\"\n",
        "        elif mejor_similitud > 0.2:\n",
        "            interpretacion = \"Baja similitud sem√°ntica\"\n",
        "        else:\n",
        "            interpretacion = \"Similitud muy baja o nula\"\n",
        "\n",
        "        print(f\"    Interpretaci√≥n: {interpretacion}\")\n",
        "\n",
        "    # Mostramos la precisi√≥n general del modelo\n",
        "    precision = aciertos / len(productos_es) * 100\n",
        "    print(f\"\\nüìà Precisi√≥n del modelo: {precision:.1f}% ({aciertos}/{len(productos_es)} aciertos)\")\n",
        "\n",
        "def demostrar_mejora_modelos(palabra_es, palabra_en, modelo):\n",
        "    \"\"\"\n",
        "    Demuestra la mejora usando embeddings multiling√ºes.\n",
        "    \"\"\"\n",
        "    print(\"\\nüß™ DEMOSTRACI√ìN: MEJORA CON EMBEDDINGS MULTILING√úES\")\n",
        "\n",
        "    # Generamos embeddings con el modelo multiling√ºe\n",
        "    vector_es = modelo.encode(palabra_es.lower())\n",
        "    vector_en = modelo.encode(palabra_en.lower())\n",
        "\n",
        "    # Calculamos similitud\n",
        "    sim = cosine_similarity(\n",
        "        vector_es.reshape(1, -1),\n",
        "        vector_en.reshape(1, -1)\n",
        "    )[0][0]\n",
        "\n",
        "    print(f\"Comparando '{palabra_es}' con '{palabra_en}' usando LaBSE:\")\n",
        "    print(f\"  ‚Ä¢ Similitud: {sim:.4f}\")\n",
        "\n",
        "    if sim > 0.8:\n",
        "        interpretacion = \"Alta similitud (excelente alineaci√≥n multiling√ºe)\"\n",
        "    elif sim > 0.6:\n",
        "        interpretacion = \"Buena similitud (alineaci√≥n efectiva)\"\n",
        "    elif sim > 0.4:\n",
        "        interpretacion = \"Similitud moderada\"\n",
        "    else:\n",
        "        interpretacion = \"Baja similitud (posible falta de alineaci√≥n)\"\n",
        "\n",
        "    print(f\"  ‚Ä¢ Interpretaci√≥n: {interpretacion}\")\n",
        "    print(f\"  ‚Ä¢ Los modelos multiling√ºes como LaBSE est√°n espec√≠ficamente entrenados\")\n",
        "    print(f\"    para alinear t√©rminos equivalentes en diferentes idiomas.\")\n",
        "\n",
        "def explicar_similitud_coseno(modelo, productos_es, productos_en, traducciones):\n",
        "    \"\"\"\n",
        "    Explica el concepto de similitud de coseno con una visualizaci√≥n usando vectores reales.\n",
        "\n",
        "    Args:\n",
        "        modelo: Modelo de embedding multiling√ºe\n",
        "        productos_es: Lista de productos en espa√±ol\n",
        "        productos_en: Lista de productos en ingl√©s\n",
        "        traducciones: Diccionario con las traducciones correctas\n",
        "    \"\"\"\n",
        "    print(\"\\nüìê EXPLICACI√ìN: SIMILITUD DE COSENO CON EMBEDDINGS MULTILING√úES\")\n",
        "    print(\"La similitud de coseno mide el √°ngulo entre dos vectores:\")\n",
        "    print(\"  ‚Ä¢ Similitud = 1: Los vectores apuntan en la misma direcci√≥n (productos id√©nticos)\")\n",
        "    print(\"  ‚Ä¢ Similitud = 0: Los vectores son perpendiculares (productos no relacionados)\")\n",
        "    print(\"  ‚Ä¢ Similitud = -1: Los vectores apuntan en direcciones opuestas (raramente ocurre)\")\n",
        "\n",
        "    # Obtener vectores reales de los modelos\n",
        "    producto_es = \"pan\"  # Producto en espa√±ol para demostraci√≥n\n",
        "    producto_en_correcto = traducciones[producto_es]  # Traducci√≥n correcta\n",
        "    producto_en_no_relacionado = \"soap\"  # Producto no relacionado\n",
        "\n",
        "    vec_es = modelo.encode(producto_es.lower())\n",
        "    vec_en_correcto = modelo.encode(producto_en_correcto.lower())\n",
        "    vec_en_no_rel = modelo.encode(producto_en_no_relacionado.lower())\n",
        "\n",
        "    # Calcular similitudes reales usando los vectores completos\n",
        "    sim_correcta = cosine_similarity(\n",
        "        vec_es.reshape(1, -1),\n",
        "        vec_en_correcto.reshape(1, -1)\n",
        "    )[0][0]\n",
        "\n",
        "    sim_no_rel = cosine_similarity(\n",
        "        vec_es.reshape(1, -1),\n",
        "        vec_en_no_rel.reshape(1, -1)\n",
        "    )[0][0]\n",
        "\n",
        "    # Reducir dimensionalidad para visualizaci√≥n (PCA a 2D)\n",
        "    pca = PCA(n_components=2)\n",
        "\n",
        "    # Juntar los vectores para aplicar PCA\n",
        "    vectores_combinados = np.vstack([vec_es, vec_en_correcto, vec_en_no_rel])\n",
        "    vectores_2d = pca.fit_transform(vectores_combinados)\n",
        "\n",
        "    # Extraer los vectores reducidos\n",
        "    vec1_2d = vectores_2d[0]  # Pan\n",
        "    vec2_2d = vectores_2d[1]  # Bread\n",
        "    vec3_2d = vectores_2d[2]  # Soap\n",
        "\n",
        "    # Crear visualizaci√≥n\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    origen = [0, 0]\n",
        "\n",
        "    # Dibujamos los vectores en 2D\n",
        "    plt.quiver(*origen, *vec1_2d, angles='xy', scale_units='xy', scale=1, color='blue',\n",
        "               label=f'{producto_es} (espa√±ol)')\n",
        "    plt.quiver(*origen, *vec2_2d, angles='xy', scale_units='xy', scale=1, color='green',\n",
        "               label=f'{producto_en_correcto} (ingl√©s) - sim:{sim_correcta:.2f}')\n",
        "    plt.quiver(*origen, *vec3_2d, angles='xy', scale_units='xy', scale=1, color='red',\n",
        "               label=f'{producto_en_no_relacionado} (ingl√©s) - sim:{sim_no_rel:.2f}')\n",
        "\n",
        "    # Configurar gr√°fico\n",
        "    plt.grid(True)\n",
        "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
        "    plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.title('Similitud de Coseno: Representaci√≥n Geom√©trica (embeddings multiling√ºes)')\n",
        "\n",
        "    # Calcular √°ngulos para dibujar arcos\n",
        "    angulo1 = np.arctan2(vec1_2d[1], vec1_2d[0])\n",
        "    angulo2 = np.arctan2(vec2_2d[1], vec2_2d[0])\n",
        "    angulo3 = np.arctan2(vec3_2d[1], vec3_2d[0])\n",
        "\n",
        "    # Dibujar arcos para mostrar √°ngulos\n",
        "    radio = 0.2 * min(np.linalg.norm(vec1_2d), np.linalg.norm(vec2_2d), np.linalg.norm(vec3_2d))\n",
        "\n",
        "    t1 = np.linspace(min(angulo1, angulo2), max(angulo1, angulo2), 100)\n",
        "    plt.plot(radio * np.cos(t1), radio * np.sin(t1), 'g-', lw=2, alpha=0.5)\n",
        "\n",
        "    t2 = np.linspace(min(angulo1, angulo3), max(angulo1, angulo3), 100)\n",
        "    plt.plot(radio * np.cos(t2), radio * np.sin(t2), 'r-', lw=2, alpha=0.5)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Explicaci√≥n matem√°tica usando los vectores reales\n",
        "    print(\"\\nF√ìRMULA MATEM√ÅTICA:\")\n",
        "    print(\"  similitud_coseno(A, B) = (A¬∑B) / (|A| √ó |B|)\")\n",
        "    print(\"Donde:\")\n",
        "    print(\"  ‚Ä¢ A¬∑B es el producto punto de los vectores\")\n",
        "    print(\"  ‚Ä¢ |A| y |B| son las magnitudes (normas) de los vectores\")\n",
        "    print(\"\\nEjemplo con vectores reales:\")\n",
        "    print(f\"  ‚Ä¢ Producto punto de '{producto_es}' y '{producto_en_correcto}': {np.dot(vec_es, vec_en_correcto):.4f}\")\n",
        "    print(f\"  ‚Ä¢ Magnitud de '{producto_es}': {np.linalg.norm(vec_es):.4f}\")\n",
        "    print(f\"  ‚Ä¢ Magnitud de '{producto_en_correcto}': {np.linalg.norm(vec_en_correcto):.4f}\")\n",
        "    print(f\"  ‚Ä¢ Similitud de coseno: {sim_correcta:.4f}\")\n",
        "    print(f\"\\nComparaci√≥n con vector no relacionado:\")\n",
        "    print(f\"  ‚Ä¢ Similitud entre '{producto_es}' y '{producto_en_no_relacionado}': {sim_no_rel:.4f}\")\n",
        "\n",
        "# ====================== FUNCI√ìN PRINCIPAL ======================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Funci√≥n principal del programa.\"\"\"\n",
        "    print(\"üõí EJERCICIO DE SIMILITUD SEM√ÅNTICA MULTILING√úE: PRODUCTOS DE SUPERMERCADO üõí\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"Este ejercicio demuestra el proceso de NLP usando embeddings multiling√ºes:\")\n",
        "    print(\"1. Normalizaci√≥n üßπ: Estandarizar el texto (min√∫sculas)\")\n",
        "    print(\"2. Vectorizaci√≥n multiling√ºe üî¢: Convertir texto a representaciones vectoriales alineadas\")\n",
        "    print(\"3. Similitud de coseno üìè: Medir la similitud sem√°ntica entre palabras en diferentes idiomas\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Definimos productos de supermercado en espa√±ol e ingl√©s\n",
        "    productos_espanol = [\"pan\", \"leche\", \"manzana\", \"cebolla\", \"jab√≥n\", \"huevos\", \"queso\"]\n",
        "    productos_ingles = [\"bread\", \"milk\", \"apple\", \"onion\", \"soap\", \"eggs\", \"cheese\"]\n",
        "\n",
        "    # Diccionario de traducciones correctas para verificaci√≥n\n",
        "    traducciones = {\n",
        "        \"pan\": \"bread\",\n",
        "        \"leche\": \"milk\",\n",
        "        \"manzana\": \"apple\",\n",
        "        \"cebolla\": \"onion\",\n",
        "        \"jab√≥n\": \"soap\",\n",
        "        \"huevos\": \"eggs\",\n",
        "        \"queso\": \"cheese\"\n",
        "    }\n",
        "\n",
        "    # Cargamos el modelo de embedding multiling√ºe\n",
        "    print(\"\\nCargando modelo de embedding multiling√ºe...\")\n",
        "    try:\n",
        "        # Cargamos el modelo LaBSE (Language-agnostic BERT Sentence Encoder)\n",
        "        # Este modelo est√° espec√≠ficamente dise√±ado para similitud sem√°ntica entre idiomas\n",
        "        modelo = SentenceTransformer('sentence-transformers/LaBSE')\n",
        "        print(\"‚úì Modelo LaBSE cargado\")\n",
        "    except Exception as e:\n",
        "        print(f\"! Error al cargar el modelo: {e}\")\n",
        "        print(\"Aseg√∫rate de tener instalada la biblioteca 'sentence-transformers':\")\n",
        "        print(\"!pip install -q sentence-transformers\")\n",
        "        return\n",
        "\n",
        "    # Demostramos la mejora usando embeddings multiling√ºes\n",
        "    demostrar_mejora_modelos(\"Pan\", \"Bread\", modelo)\n",
        "\n",
        "    # Calculamos la similitud entre productos\n",
        "    matriz_similitud, vectores_es, vectores_en = calcular_similitud_productos(\n",
        "        productos_espanol,\n",
        "        productos_ingles,\n",
        "        traducciones,\n",
        "        modelo\n",
        "    )\n",
        "\n",
        "    # Explicamos la similitud de coseno usando vectores reales\n",
        "    explicar_similitud_coseno(modelo, productos_espanol, productos_ingles, traducciones)\n",
        "\n",
        "    print(\"\\nüí° CONCLUSI√ìN\")\n",
        "    print(\"Este ejercicio muestra c√≥mo los embeddings multiling√ºes mejoran significativamente\")\n",
        "    print(\"la detecci√≥n de equivalencias sem√°nticas entre palabras de diferentes idiomas.\")\n",
        "    print(\"Observaciones importantes:\")\n",
        "    print(\"1. Los embeddings multiling√ºes (LaBSE) est√°n espec√≠ficamente entrenados para\")\n",
        "    print(\"   alinear palabras con el mismo significado en diferentes idiomas.\")\n",
        "    print(\"2. Esto se refleja en valores de similitud mucho m√°s altos para traducciones correctas.\")\n",
        "    print(\"3. La matriz de similitud ahora muestra una clara diagonal de valores altos, lo que\")\n",
        "    print(\"   indica una correcta identificaci√≥n de productos equivalentes.\")\n",
        "    print(\"4. Esta tecnolog√≠a es fundamental en aplicaciones modernas de PLN como:\")\n",
        "    print(\"   - B√∫squeda y recuperaci√≥n de informaci√≥n multiling√ºe\")\n",
        "    print(\"   - Sistemas de recomendaci√≥n internacionales\")\n",
        "    print(\"   - Traducci√≥n autom√°tica de alta calidad\")\n",
        "    print(\"   - Asistentes virtuales multiling√ºes\")\n",
        "\n",
        "# ====================== EJECUCI√ìN DEL PROGRAMA ======================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "REHFXwozdyzO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
